{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a59b6d36",
   "metadata": {},
   "source": [
    "# Rag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64f1e9c",
   "metadata": {},
   "source": [
    "## Проверка gigachata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a0c7a5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "023235af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "credentials = os.getenv('credentials')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc05cf87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models.gigachat import GigaChat\n",
    "\n",
    "llm = GigaChat(auth_url = 'https://sm-auth-sd.prom-88-89-apps.ocp-geo.ocp.sigma.sbrf.ru/api/v2/oauth',credentials=credentials, verify_ssl_certs=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a50dee6",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://token:****@sberosc.sigma.sbrf.ru/repo/pypi/simple\n",
      "Requirement already satisfied: langchain-community in c:\\anaconda3\\lib\\site-packages (0.2.16)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\anaconda3\\lib\\site-packages (from langchain-community) (3.10.5)\n",
      "Requirement already satisfied: langchain<0.3.0,>=0.2.16 in c:\\anaconda3\\lib\\site-packages (from langchain-community) (0.2.16)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\anaconda3\\lib\\site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.38 in c:\\anaconda3\\lib\\site-packages (from langchain-community) (0.2.38)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in c:\\anaconda3\\lib\\site-packages (from langchain-community) (0.1.116)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in c:\\anaconda3\\lib\\site-packages (from langchain-community) (8.5.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\anaconda3\\lib\\site-packages (from langchain-community) (6.0)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\anaconda3\\lib\\site-packages (from langchain-community) (1.20.3)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\anaconda3\\lib\\site-packages (from langchain-community) (1.4.22)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\anaconda3\\lib\\site-packages (from langchain-community) (2.27.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in c:\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.11.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.5)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (21.2.0)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.22.0)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in c:\\anaconda3\\lib\\site-packages (from langchain<0.3.0,>=0.2.16->langchain-community) (0.2.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\anaconda3\\lib\\site-packages (from langchain<0.3.0,>=0.2.16->langchain-community) (2.9.0)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\anaconda3\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.38->langchain-community) (24.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\anaconda3\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.38->langchain-community) (1.33)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\anaconda3\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.38->langchain-community) (4.12.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.38->langchain-community) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.0->langchain-community) (3.10.7)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.0->langchain-community) (0.27.2)\n",
      "Requirement already satisfied: idna in c:\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-community) (3.2)\n",
      "Requirement already satisfied: certifi in c:\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-community) (2021.10.8)\n",
      "Requirement already satisfied: sniffio in c:\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-community) (1.2.0)\n",
      "Requirement already satisfied: anyio in c:\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-community) (2.2.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-community) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-community) (0.14.0)\n",
      "Requirement already satisfied: tzdata in c:\\anaconda3\\lib\\site-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.16->langchain-community) (2024.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\anaconda3\\lib\\site-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.16->langchain-community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.2 in c:\\anaconda3\\lib\\site-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.16->langchain-community) (2.23.2)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain-community) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain-community) (1.26.7)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain-community) (1.1.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\anaconda3\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (0.4.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ygments (c:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ygments (c:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ygments (c:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ygments (c:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ygments (c:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ygments (c:\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "! pip install -U langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "077f1a4e",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://token:****@sberosc.sigma.sbrf.ru/repo/pypi/simple\n",
      "Requirement already satisfied: gigachat in c:\\anaconda3\\lib\\site-packages (0.1.35)\n",
      "Requirement already satisfied: pydantic>=1 in c:\\anaconda3\\lib\\site-packages (from gigachat) (2.9.0)\n",
      "Requirement already satisfied: httpx<1 in c:\\anaconda3\\lib\\site-packages (from gigachat) (0.27.2)\n",
      "Requirement already satisfied: sniffio in c:\\anaconda3\\lib\\site-packages (from httpx<1->gigachat) (1.2.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\anaconda3\\lib\\site-packages (from httpx<1->gigachat) (1.0.5)\n",
      "Requirement already satisfied: certifi in c:\\anaconda3\\lib\\site-packages (from httpx<1->gigachat) (2021.10.8)\n",
      "Requirement already satisfied: idna in c:\\anaconda3\\lib\\site-packages (from httpx<1->gigachat) (3.2)\n",
      "Requirement already satisfied: anyio in c:\\anaconda3\\lib\\site-packages (from httpx<1->gigachat) (2.2.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1->gigachat) (0.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\anaconda3\\lib\\site-packages (from pydantic>=1->gigachat) (4.12.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\anaconda3\\lib\\site-packages (from pydantic>=1->gigachat) (0.7.0)\n",
      "Requirement already satisfied: tzdata in c:\\anaconda3\\lib\\site-packages (from pydantic>=1->gigachat) (2024.1)\n",
      "Requirement already satisfied: pydantic-core==2.23.2 in c:\\anaconda3\\lib\\site-packages (from pydantic>=1->gigachat) (2.23.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ygments (c:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ygments (c:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ygments (c:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ygments (c:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ygments (c:\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ygments (c:\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "! pip install gigachat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b46876a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Винни-Пух — персонаж английских детских стихов Алана Милна и серии книг о нём, а также их экранизаций. Он медвежонок, живущий в лесу вместе с другими животными. В книгах Милн рассказывает о его приклю'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.schema import HumanMessage\n",
    "\n",
    "question = \"Кто такой Винни-пух?\"\n",
    "llm([HumanMessage(content=question)]).content[0:200]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb226cd9",
   "metadata": {},
   "source": [
    "## Парсинг и pdf loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f1c793b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CURL_CA_BUNDLE'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "691b0a7e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "art = []\n",
    "url = 'https://ai.gov.ru/knowledgebase/'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "article_links = soup.find_all('a', {'class': 'knowledgeBaseCard__title'})\n",
    "for article_link in article_links:\n",
    "    article_url = article_link.get('href')\n",
    "    art.append(article_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ea19d9f",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/knowledgebase/dokumenty-po-razvitiyu-ii-v-rf/nacionalynaya_strategiya_razvitiya_iskusstvennogo_intellekta_na_period_do_2030_goda/',\n",
       " '/knowledgebase/samoregulirovanie-ii/2024_iniciativa_po_samoregulirovaniyu_v_industrii_generativnogo_ii/',\n",
       " '/knowledgebase/iyuly_2024_shanhayskaya_deklaraciya_o_globalynom_upravlenii_iskusstvennym_intellektom/',\n",
       " '/knowledgebase/vnedrenie-ii/2024_sostoyanie_industrii_bolyshih_ii-modeley_v_kitae/',\n",
       " '/knowledgebase/standarty-i-sertifikatsiya-ii/2024_rukovodstvo_po_sozdaniyu_kompleksnoy_sistemy_standartizacii_dlya_nacionalynoy_industrii_iskusstvennogo_intellekta_knr/',\n",
       " '/knowledgebase/2024_prognoz_perspektiv_razvitiya_i_strategicheskoe_planirovanie_investicii_v_industriyu_aigc/',\n",
       " '/knowledgebase/dokumenty-po-razvitiyu-ii-v-drugikh-stranakh/2024_znachenie_ii_v_ekonomike_oae/',\n",
       " '/knowledgebase/strategicheskie-dokumenty-po-ii-v-drugikh-stranakh/iyuly_2024_obnovlennaya_strategiya_nato_po_ii/',\n",
       " '/knowledgebase/investitsionnaya-aktivnost/2024_vliyanie_ii_na_rabotu_i_zanyatosty_the_impact_of_ai_on_work_and_employment_international_organisation_of_employers/',\n",
       " '/knowledgebase/investitsionnaya-aktivnost/2024_ramochnaya_konvenciya_po_globalynym_problemam_ii_framework_convention_on_global_ai_challenges_cigi/']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "art"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef976cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_links = []\n",
    "for link in art:\n",
    "    url_pdf = 'https://ai.gov.ru' + link\n",
    "    pdf_links.append(url_pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7703eb4a",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://ai.gov.ru/knowledgebase/dokumenty-po-razvitiyu-ii-v-rf/nacionalynaya_strategiya_razvitiya_iskusstvennogo_intellekta_na_period_do_2030_goda/',\n",
       " 'https://ai.gov.ru/knowledgebase/samoregulirovanie-ii/2024_iniciativa_po_samoregulirovaniyu_v_industrii_generativnogo_ii/',\n",
       " 'https://ai.gov.ru/knowledgebase/iyuly_2024_shanhayskaya_deklaraciya_o_globalynom_upravlenii_iskusstvennym_intellektom/',\n",
       " 'https://ai.gov.ru/knowledgebase/vnedrenie-ii/2024_sostoyanie_industrii_bolyshih_ii-modeley_v_kitae/',\n",
       " 'https://ai.gov.ru/knowledgebase/standarty-i-sertifikatsiya-ii/2024_rukovodstvo_po_sozdaniyu_kompleksnoy_sistemy_standartizacii_dlya_nacionalynoy_industrii_iskusstvennogo_intellekta_knr/',\n",
       " 'https://ai.gov.ru/knowledgebase/2024_prognoz_perspektiv_razvitiya_i_strategicheskoe_planirovanie_investicii_v_industriyu_aigc/',\n",
       " 'https://ai.gov.ru/knowledgebase/dokumenty-po-razvitiyu-ii-v-drugikh-stranakh/2024_znachenie_ii_v_ekonomike_oae/',\n",
       " 'https://ai.gov.ru/knowledgebase/strategicheskie-dokumenty-po-ii-v-drugikh-stranakh/iyuly_2024_obnovlennaya_strategiya_nato_po_ii/',\n",
       " 'https://ai.gov.ru/knowledgebase/investitsionnaya-aktivnost/2024_vliyanie_ii_na_rabotu_i_zanyatosty_the_impact_of_ai_on_work_and_employment_international_organisation_of_employers/',\n",
       " 'https://ai.gov.ru/knowledgebase/investitsionnaya-aktivnost/2024_ramochnaya_konvenciya_po_globalynym_problemam_ii_framework_convention_on_global_ai_challenges_cigi/']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a733c3a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://ai.gov.ru/knowledgebase/standarty-i-sertifikatsiya-ii/2024_rukovodstvo_po_sozdaniyu_kompleksnoy_sistemy_standartizacii_dlya_nacionalynoy_industrii_iskusstvennogo_intellekta_knr/',\n",
       " 'https://ai.gov.ru/knowledgebase/2024_prognoz_perspektiv_razvitiya_i_strategicheskoe_planirovanie_investicii_v_industriyu_aigc/']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_links[4:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f191ce5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/upload/iblock/7d1/zzo35d3eynv1ux65j4ubv9vounu2a5k1.pdf\n",
      "/upload/iblock/700/yagzsfbkmdntfwgh6bvhbnm129ad2guo.pdf\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['https://ai.gov.ru/upload/iblock/7d1/zzo35d3eynv1ux65j4ubv9vounu2a5k1.pdf',\n",
       " 'https://ai.gov.ru/upload/iblock/700/yagzsfbkmdntfwgh6bvhbnm129ad2guo.pdf']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_toload = []\n",
    "for i in pdf_links[8:10]:\n",
    "    response = requests.get(i)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    pdf = soup.select_one('.docListCard')\n",
    "    print(pdf['href'])\n",
    "    pdf_toload.append('https://ai.gov.ru' + pdf['href'])\n",
    "pdf_toload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e179a50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# response = requests.get(pdf_toload[0])\n",
    "# file_Path = 'research_Paper_1.pdf'\n",
    "# if response.status_code == 200:\n",
    "#     with open(file_Path, 'wb') as file:\n",
    "#         file.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2af95ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_Path = 'C:\\Work\\Rag\\papers'\n",
    "c = 0\n",
    "for i in pdf_toload:\n",
    "    response_load = requests.get(i)\n",
    "#     file_Path = 'C:\\Work\\Rag_bot-master\\papers'\n",
    "    with open(file_Path + f\"\\paper{c}.pdf\", 'wb') as file:\n",
    "        file.write(response_load.content)\n",
    "    c+=1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "48e9b4f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://ai.gov.ru/upload/iblock/7d1/zzo35d3eynv1ux65j4ubv9vounu2a5k1.pdf',\n",
       " 'https://ai.gov.ru/upload/iblock/700/yagzsfbkmdntfwgh6bvhbnm129ad2guo.pdf']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_toload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "597863f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_community.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "ba6426ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loader = PyPDFLoader(file_path=file_Path + '\\paper0.pdf')# если сканы extract_images=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "e0049932",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# dc = loader.load()\n",
    "# dc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "9eb44945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c5ef1d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# documents = loader.load_and_split()\n",
    "\n",
    "# text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "\n",
    "# splitted_data = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8030a305",
   "metadata": {},
   "source": [
    "## Эмбеддинги и векторная дб"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b6682dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "# from langchain.vectorstores.faiss import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "779d8240",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ! pip install -U langchain-huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6b74c3f5",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ! pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5a06c5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #выбор эмбеддинговой модели\n",
    "# #https://github.com/avidale/encodechka#%D0%BB%D0%B8%D0%B4%D0%B5%D1%80%D0%B1%D0%BE%D1%80%D0%B4\n",
    "# model_name = \"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\"\n",
    "# model_kwargs = {'device': 'cpu'}\n",
    "# encode_kwargs = {'normalize_embeddings': False}\n",
    "# embedding = HuggingFaceEmbeddings(model_name=model_name,\n",
    "#                                   model_kwargs=model_kwargs,\n",
    "#                                   encode_kwargs=encode_kwargs)\n",
    "# #векторная бд\n",
    "# vector_store = FAISS.from_documents(splitted_data, embedding=embedding)\n",
    "# embedding_retriever = vector_store.as_retriever(search_kwargs={'k': 3}, search_type=\"mmr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955c07bb",
   "metadata": {},
   "source": [
    "## Модель и ответы\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0235dbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_core.prompts import ChatPromptTemplate\n",
    "# from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "# from langchain.chains import create_retrieval_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b095bd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm = GigaChat(credentials=credentials,auth_url = 'https://sm-auth-sd.prom-88-89-apps.ocp-geo.ocp.sigma.sbrf.ru/api/v2/oauth',\n",
    "#                    verify_ssl_certs=False\n",
    "#                    )\n",
    "# # prompt = ChatPromptTemplate.from_template('''Ответь на вопрос пользователя. \\\n",
    "# # Используй при этом только информацию из контекста. Если в контексте нет \\\n",
    "# # информации для ответа, сообщи об этом пользователю.\n",
    "# # Контекст: {context}\n",
    "# # Вопрос: {input}\n",
    "# # Ответ:''')\n",
    "# prompt = ChatPromptTemplate.from_template('''Ответь на вопрос пользователя. \\\n",
    "# Используй при этом только информацию из контекста. \n",
    "# Контекст: {context}\n",
    "# Вопрос: {input}\n",
    "# Ответ:''')\n",
    "#eqw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "15120687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# question = 'Расскажи про ИИ'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4ec9d5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# document_chain = create_stuff_documents_chain(\n",
    "#         llm=llm,\n",
    "#         prompt=prompt\n",
    "#         )\n",
    "# retrieval_chain = create_retrieval_chain(embedding_retriever, document_chain)\n",
    "# #     #ответ модели ssda\n",
    "# # sim = vector_store.similarity_search(f'{question}', k=3)# похожие чанки\n",
    "# resp = retrieval_chain.invoke({'input': question})\n",
    "# print(resp['answer'])\n",
    "# # print(f'Ответ может быть в этом отрывке ', resp['context'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "aa323cc2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(resp[\"context\"][0].metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "eef567f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loader2 = PyPDFLoader(file_path=file_Path + '\\paper1.pdf')# если сканы extract_images=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0b3336e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# documents2 = loader2.load_and_split()\n",
    "\n",
    "# # text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "\n",
    "# splitted_data2 = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ad205541",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# vector_store.add_documents(splitted_data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1b86520c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_community.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8d8ea275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loader = PyPDFLoader(file_path=file_Path + '\\paper9.pdf')# если сканы extract_images=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7dec58cd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# dc = loader.load()\n",
    "# dc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6f0ad1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9b846208",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ! pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1d572a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size=1000, chunk_overlap=100, is_separator_regex=False)\n",
    "# documents = loader.load_and_split(text_splitter=text_splitter)\n",
    "\n",
    "\n",
    "\n",
    "# splitted_data = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "20c8bb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = \"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\"\n",
    "# model_kwargs = {'device': 'cpu'}\n",
    "# encode_kwargs = {'normalize_embeddings': False}\n",
    "# embedding = HuggingFaceEmbeddings(model_name=model_name,\n",
    "#                                   model_kwargs=model_kwargs,\n",
    "#                                   encode_kwargs=encode_kwargs)\n",
    "# #векторная бд\n",
    "# vector_store = FAISS.from_documents(splitted_data, embedding=embedding)\n",
    "# embedding_retriever = vector_store.as_retriever(search_kwargs={'k': 3}, search_type=\"mmr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c386210e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm = GigaChat(credentials=credentials,auth_url = 'https://sm-auth-sd.prom-88-89-apps.ocp-geo.ocp.sigma.sbrf.ru/api/v2/oauth',\n",
    "#                    verify_ssl_certs=False\n",
    "#                    )\n",
    "# # prompt = ChatPromptTemplate.from_template('''Ответь на вопрос пользователя. \\\n",
    "# # Используй при этом только информацию из контекста. Если в контексте нет \\\n",
    "# # информации для ответа, сообщи об этом пользователю.\n",
    "# # Контекст: {context}\n",
    "# # Вопрос: {input}\n",
    "# # Ответ:''')\n",
    "# prompt = ChatPromptTemplate.from_template('''Ответь на вопрос пользователя. \\\n",
    "# Используй при этом только информацию из контекста. \n",
    "# Контекст: {context}\n",
    "# Вопрос: {input}\n",
    "# Ответ:''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "079dfc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# question = 'Как ии поможет развитию в ОАЭ'\n",
    "# document_chain = create_stuff_documents_chain(\n",
    "#         llm=llm,\n",
    "#         prompt=prompt\n",
    "#         )\n",
    "# retrieval_chain = create_retrieval_chain(embedding_retriever, document_chain)\n",
    "# #     #ответ модели\n",
    "# # sim = vector_store.similarity_search(f'{question}', k=3)# похожие чанки\n",
    "# resp = retrieval_chain.invoke({'input': question})\n",
    "# print(resp['answer'])\n",
    "# # print(f'Ответ может быть в этом отрывке ', resp['context'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "174f3125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resp['context']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1ad60b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_community.document_loaders import PyPDFLoader\n",
    "# from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "# from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "# from langchain.vectorstores.faiss import FAISS\n",
    "# from langchain_core.prompts import ChatPromptTemplate\n",
    "# from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "# from langchain.chains import create_retrieval_chain\n",
    "# from langchain.chat_models.gigachat import GigaChat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ff16c563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_Path = 'C:\\Work\\Rag_bot-master\\papers'\n",
    "# docs = []\n",
    "# for i in range(10):   \n",
    "#     loader = PyPDFLoader(file_path=file_Path + f'\\paper{i}.pdf')\n",
    "#     documents = loader.load_and_split()\n",
    "#     text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100, is_separator_regex=False)\n",
    "#     splitted_data = text_splitter.split_documents(documents)\n",
    "#     docs.extend(splitted_data)\n",
    "# model_name = \"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\"\n",
    "# model_kwargs = {'device': 'cpu'}\n",
    "# encode_kwargs = {'normalize_embeddings': False}\n",
    "# embedding = HuggingFaceEmbeddings(model_name=model_name,\n",
    "#                                   model_kwargs=model_kwargs,\n",
    "#                                   encode_kwargs=encode_kwargs)\n",
    "# #векторная бд\n",
    "# vector_store = FAISS.from_documents(docs, embedding=embedding)\n",
    "# embedding_retriever = vector_store.as_retriever(search_kwargs={'k': 3}, search_type=\"mmr\")\n",
    "# %%time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a9dd13c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# llm = GigaChat(credentials=credentials,auth_url = 'https://sm-auth-sd.prom-88-89-apps.ocp-geo.ocp.sigma.sbrf.ru/api/v2/oauth',\n",
    "#                    verify_ssl_certs=False\n",
    "#                    )\n",
    "# # prompt = ChatPromptTemplate.from_template('''Ответь на вопрос пользователя. \\\n",
    "# # Используй при этом только информацию из контекста. Если в контексте нет \\\n",
    "# # информации для ответа, сообщи об этом пользователю.\n",
    "# # Контекст: {context}\n",
    "# # Вопрос: {input}\n",
    "# # Ответ:''')\n",
    "# prompt = ChatPromptTemplate.from_template('''Ответь на вопрос пользователя. \\\n",
    "# Используй при этом только информацию из контекста. \n",
    "# Контекст: {context}\n",
    "# Вопрос: {input}\n",
    "# Ответ:''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "41380e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# question = 'Как ии поможет развитию в ОАЭ'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c451e270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# document_chain = create_stuff_documents_chain(\n",
    "#         llm=llm,\n",
    "#         prompt=prompt\n",
    "#         )\n",
    "# retrieval_chain = create_retrieval_chain(embedding_retriever, document_chain)\n",
    "# #     #ответ модели\n",
    "# # sim = vector_store.similarity_search(f'{question}', k=3)# похожие чанки\n",
    "# resp = retrieval_chain.invoke({'input': question})\n",
    "# print(resp['answer'])\n",
    "# # print(f'Ответ может быть в этом отрывке ', resp['context'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "dcd894cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resp['context']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d3d2610e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vector_store.save_local(file_Path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e0a7b279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vector_store2 = FAISS.load_local(folder_path=file_Path, embeddings=embedding, allow_dangerous_deserialization= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "aa57abed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding_retriever2 = vector_store2.as_retriever(search_kwargs={'k': 4}, search_type=\"mmr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0f5f2c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# question2 = 'Как ии поможет развитию в ОАЭ'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "422468af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# document_chain = create_stuff_documents_chain(\n",
    "#         llm=llm,\n",
    "#         prompt=prompt\n",
    "#         )\n",
    "# retrieval_chain = create_retrieval_chain(embedding_retriever2, document_chain)\n",
    "# #     #ответ модели\n",
    "# # sim = vector_store.similarity_search(f'{question}', k=3)# похожие чанки\n",
    "# resp = retrieval_chain.invoke({'input': question2})\n",
    "# print(resp['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2ed060ab",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# resp['context']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "00c06aaf",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from langchain_community.document_loaders import OnlinePDFLoader\n",
    "\n",
    "# loaderon = OnlinePDFLoader(\"https://ai.gov.ru/upload/iblock/e6f/8n3v10smpbdamb3l4qmls6z2tjhszis1.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9f527ae9",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ! pip install unstructured[pdf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "71b68feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "loaderdir = PyPDFDirectoryLoader(path=file_Path)\n",
    "docdir = loaderdir.load_and_split(text_splitter=RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7e525e45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper0.pdf', 'page': 0}, page_content='1\\nAnalysis of Business Environment in Least Developed Countries\\nThe Impact of AI on Work and Employment \\nJune 2024POLICY REVIEW'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper0.pdf', 'page': 1}, page_content='2\\nThis publication was produced with the financial support of the European Union. Its contents are the sole \\nresponsibility of the International Organisation of Employers (IOE) and do not necessarily reflect the views \\nof the European Union.'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper0.pdf', 'page': 2}, page_content='3\\nTable of contents \\nI. Factsheet 4\\nII. Introduction 6\\nIII. Trends in AI and Employment  8\\nIV . Trends in AI and Labour Management  12\\nV . Policy Challenges and Responses on AI at Work 14\\nVI. Recommendations and Priorities for Employers’ Organisations  \\nand Governments 17\\nVII. References 20'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper0.pdf', 'page': 3}, page_content='4\\nArtificial intelligence (AI) refers to systems that can process information, \\nlearn from it, and use that learning to generate outputs and achieve goals \\n(Kaplan and Haenlein, 2019). Generative artificial intelligence involves using \\nvarious models to create content such as text, images, video, or sound. Generative \\nAI has the potential to contribute between $2.6 trillion and $4.4 trillion annually to \\nthe global economy, highlighting its positive economic effects \\n(McKinsey & Company, 2023).\\nThe key impacts of AI on employment are related to job displacement, \\naugmentation, and creation. While some jobs may be displaced, others will \\nsee growth due to AI implementation, particularly in fields like AI modelling and \\nbusiness intelligence (WEF, 2023a). There is strong potential for the creation of new \\njobs, as can be observed over recent years. Generative AI models may increase \\nthe value of jobs requiring social interactions, while the augmentation potential'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper0.pdf', 'page': 3}, page_content='the value of jobs requiring social interactions, while the augmentation potential \\nof AI is deemed larger than its automation potential, affecting a wide range of \\ntasks across various job types (Gmyrek, Berg and Bescond, 2023). Globally, most \\nCEOs (69 per cent) recognise the need for their workforce to develop new skills to \\nleverage generative AI effectively (PwC, 2024). \\nAmong the benefits associated to this technology, AI can enhance productivity \\nacross industries, with potential annual global productivity increases of 0.2 \\nper cent to 3.3 per cent (McKinsey & Company, 2023). In relation to job quality, \\nwhile ethical concerns about AI-based monitoring exist, AI can also improve jobs \\nthrough reduced tedium, greater engagement, and enhanced safety, exemplified \\nby its use in predicting workplace accidents (Luo et al., 2023) and in personalising \\ntraining through AI-based virtual tools (Chen, 2023).\\nAdoption rates vary, with larger companies leading the way and smaller'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper0.pdf', 'page': 3}, page_content='Adoption rates vary, with larger companies leading the way and smaller \\nones still in the exploration phase. Globally, it is projected that 74.9 per cent of \\ncompanies will have adopted AI by 2027, with 59 per cent foreseeing its growing \\nsignificance in their business strategies (WEF, 2023a). AI is increasingly used in \\nhiring processes, performance management, conflict resolution, and downsizing \\ninitiatives across various industries. While it offers benefits, ethical concerns \\nregarding data validity, privacy, and bias in decision-making require careful \\nconsideration.I. Factsheet'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper0.pdf', 'page': 4}, page_content='5\\nGlobal AI policies have aimed to establish normative frameworks and \\nprinciples. The ILO Centenary Declaration for the Future of Work, OECD AI \\nPrinciples, UNESCO AI Recommendation are examples. Regional organisations \\nare developing guidelines for AI governance with a focus on human-centred \\napproaches. The EU’s AI Act, agreed in December 2023, introduces hard-law \\nregulation based on risk classification for AI systems, applicable to both public \\nand private entities in the EU market. It will have phased implementation and \\nenforcement by EU countries.\\nGovernments have created national AI strategies focused on competitiveness \\nand fairness. Initiatives have concentrated on creating institutional capacity, \\nstimulating adoption in public and private sectors, and addressing AI ethics and \\ntransparency. Firms have been targeted through direct and indirect support \\nmeasures such as R&D investment, skills strategies, and data protection legislation \\n(OECD, 2024).'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper0.pdf', 'page': 5}, page_content='6\\nII. Introduction\\nArtificial intelligence (AI) technologies hold great promise as catalysts for social and \\neconomic change in a broader context of digital transformation. AI technologies have \\nthe potential to transform businesses, industries, labour markets, and society at large. \\nWhile there are still obstacles to its application, generative AI systems can provide value \\nto customers, optimise processes, supplement human knowledge by providing insights \\nand solutions, and help businesses develop or maintain a competitive advantage. As the \\nneed for more strategic involvement and adaptation becomes a reality, employers must \\nhave the necessary tools and insights to make informed decisions on the right pathways \\nthat develop businesses and enhance employment.\\nIn this scenario, the purpose of this report is to synthetise existing research about the \\nimpact of AI on work and employment, providing strategic knowledge for employers to'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper0.pdf', 'page': 5}, page_content='impact of AI on work and employment, providing strategic knowledge for employers to \\nnavigate its development. While the effects of technology on labour markets are complex \\nand ever-changing, there is a significant body of research that can guide employers’ \\ndecision-making and offer insights into the various dimensions characterising the current \\nprocess of AI expansion. In this introduction, the report analyses the basic aspects of this \\ntechnology and the emergence of generative AI in recent years. Section III. responds to \\nkey questions about the potential implications of AI for employment with a global focus. \\nSection IV. unpacks some of the current uses of AI in labour management, their potential \\nbenefits and risks. Section V. analyses the policy landscape of AI with reference to \\ninternational and national initiatives. Lastly, the report concludes with recommendations \\nfor employers and governments regarding AI development and advocacy. \\n1. What is artificial intelligence?'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper0.pdf', 'page': 5}, page_content='1. What is artificial intelligence?\\nArtificial intelligence (AI) is “a system’s ability to interpret external data correctly, to \\nlearn from such data, and to use those learnings to achieve specific goals and tasks \\nthrough flexible adaptation” (Kaplan and Haenlein, 2019).  The modern conception of \\nAI refers to “agents” or systems that can perform actions based on their perception of \\nthe environment (Russell and Norvig, 2020). Inspired by this conception that sees AI \\nsystems as agents, the OECD has defined AI as a machine-based system that, for explicit \\nor implicit objectives, infers how to create outputs from the inputs it receives (e.g., data), \\ndelivering predictions, content, recommendations, or decisions as a result.1  Even though \\ndefinitions of AI tend to highlight the processing of information and its results, the OECD’s \\ndefinition also emphasises the importance of looking at its objectives, as AI systems can'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper0.pdf', 'page': 5}, page_content='definition also emphasises the importance of looking at its objectives, as AI systems can \\nbe assessed as beneficial or not based on the aims that are set for them (Russell, 2019).\\n2. What is generative artificial intelligence?\\nWhereas the understanding of AI as “making machines capable of simulating \\nintelligence” is straightforward and uncontroversial (Wamba-Taguimdje et al., 2020), there \\nare recurrent issues in the history of AI that have been subject to societal discussion, \\nsuch as job displacements, failings in automated systems and privacy protections \\n(Buchanan, 2005). Current debates revolve around similar issues, but this time the impact \\nof “generative AI” is in the spotlight. Generative AI uses different models as a foundation \\nto create content in formats such as text, images, video or sound. The most resonant of \\nthem at present are “large language models” (LLMs) such as Chat-GPT or Gemini. LLMs'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper0.pdf', 'page': 5}, page_content='them at present are “large language models” (LLMs) such as Chat-GPT or Gemini. LLMs \\n“can process massive amounts of unstructured text and learn the relationships between \\nwords or portions of words” (McKinsey & Company, 2023, p. 6), allowing them to generate \\nnew content that simulate natural language. Generative AI, while displaying great \\n1 See: https://oecd.ai/en/wonk/ai-system-definition-update'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper0.pdf', 'page': 6}, page_content='7\\npotential, also faces issues of reliability due to “hallucinations” (incorrect or misleading \\nresults that AI models generate) that sound plausible, and copyright concerns. Creators \\nwhose data has fed LLM training may challenge the use of their material, potentially \\nexposing users to legal risks (Shanbhogue 2023). Efforts should be made to avoid \\nmisinformation as much as possible.\\nFurthermore, many AI researchers say that fakes will become undetectable. An article \\nfrom The Economist talks about fake images, videos and advertisements, etc, as one of \\nthe main challenges. The latest software to detect these fakes fail to do so. There is an \\nassumption that AI-generated images or videos will leave a trace. This is not the case. It is \\ngetting harder and harder for humans to tell the difference between a real image or video \\nand a fake one. Even the best-performing programme failed to correctly spot computer-'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper0.pdf', 'page': 6}, page_content='and a fake one. Even the best-performing programme failed to correctly spot computer-\\ngenerated images 13 per cent of the time (though that was better than the humans, who \\nerred in 39 per cent of cases). Detecting text is slightly better. Watermarking, which is the \\npractice of imperceptibly altering a piece of data in order to embed information about \\nthe data, such as tweaking the pixels in subtle ways or shifting their colours, can be useful \\nto enable humans to see the difference. More research is needed on various ways to allow \\nsoftware to detect fake media as this can also impact the world of work.\\n3. What makes generative AI different from previous AI advances?\\nSeveral factors have made generative AI innovations particularly impactful for the \\neconomy. The first of them is that they offer applications in a wide range of activities and \\nindustries. As a Deloitte report suggests: \\nApart from its versatility, generative AI has enjoyed widespread use since Chat-GPT was'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper0.pdf', 'page': 6}, page_content='Apart from its versatility, generative AI has enjoyed widespread use since Chat-GPT was \\nlaunched in November 2022. The second factor, then, has to do with the high accessibility \\nof current AI-powered applications for content creation, and their reduced cost. A survey \\nfrom 2022, previous to the release of Chat-GPT , showed that 53 per cent of employers in \\nfinance and 58 per cent of them in manufacturing within OECD countries cited the main \\nbarrier to AI adoption was the “high costs of technology” (Lane, Williams and Broecke, \\n2023, p. 85). Web-based applications that rely on generative AI are a game-changer in that \\nsense as they are often free to use or just require a membership. In this regard, generative \\nAI could add between $2.6 trillion to $4.4 trillion to the global economy every year, \\nMcKinsey has reported, reinforcing the positive economic potential of this technology \\n(McKinsey & Company, 2023).  Around three-fourths of this added value would be about'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper0.pdf', 'page': 6}, page_content='(McKinsey & Company, 2023).  Around three-fourths of this added value would be about \\n“customer operations, marketing and sales, software engineering, and R&D (McKinsey \\n& Company, 2023, p. 39). Still, rates of adoption will vary across countries and regions, \\nas well as across enterprises of different sectors and sizes, making its effects spread \\nunevenly (Cazzaniga et al., 2024).“AI took a major leap with Generative AI and its ability to disrupt the way we \\nwork because of its ability to create content that profoundly supports human \\nexpertise and skills—writing memos and reports, designing website graphics, \\ncreating personalized marketing strategies, and curating employee learning \\nprograms, for example.” \\n(Deloitte, 2023, p. 3)“'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper0.pdf', 'page': 7}, page_content='8\\n4. How will AI impact employment in \\nthe future?\\nFor the past decade, analyses have tended \\nto either highlight labour substitution \\n- the “doomsayer’s perspective” or the \\nefficiency gains and new types of work \\nderived from AI implementation - the \\n“optimist’s perspective” (Frank et al., \\n2019). From a more balanced approach, \\nit is suggested that AI has at least three \\neffects on employment: job displacement, \\naugmentation and creation (Gilbert, \\n2023). Regarding the latter, 50 per cent of \\nemployers worldwide expect AI to promote \\njob growth in the next five years (WEF, \\n2023a, p. 6). \\nFor employers, the fastest-growing jobs \\nby 2027 will be AI and machine learning \\nspecialists, sustainability analysts and \\nbusiness intelligence analysts (WEF, 2023a). \\nApart from increasing demand for already-\\nexisting jobs, AI-induced employment \\ngrowth is expected to be also driven by the \\nemergence of new occupations: prompt \\nengineers, AI modellers, data trainers, as'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper0.pdf', 'page': 7}, page_content='emergence of new occupations: prompt \\nengineers, AI modellers, data trainers, as \\nwell as governance and ethics specialists \\nare some examples (WEF, 2023b). \\nOccupations that require in-person and \\nsocial interactions will become increasingly \\nvaluable, especially with the rise of \\ngenerative AI models, as there are “key \\nbottlenecks to the automation of social \\ntasks” (Frey and Osborne, 2023, p. 3). At the \\nsame time, many jobs will be “insulated” \\nfrom AI innovations, at least in terms of \\ntheir core skills, for instance in healthcare, \\nconstruction or hospitality (LinkedIn, 2023).\\nSince generative AI could have significant \\nimplications for a wide range of work-\\nrelated tasks, it will affect job demand. The \\naugmentation potential is significantly larger \\nthan the automation potential: ILO research \\nestimates that while 13 per cent of jobs in \\nthe world could be boosted by AI, only 2.3 \\nper cent could be fully automated at present'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper0.pdf', 'page': 7}, page_content='the world could be boosted by AI, only 2.3 \\nper cent could be fully automated at present \\n(Gmyrek, Berg and Bescond, 2023, p. 34). III. Trends in AI and Employment \\nPrior to the breakthrough of generative AI, \\nanalysts had assumed that mainly routine \\nmanual and cognitive work was going to be \\naffected by AI and automation (Acemoglu \\nand Autor, 2010), predicting that this was \\ngoing to create an increasing demand for \\ncreative jobs and data analysts. Given the rise \\nof generative AI tools that can excel at both \\ncreative and analytic tasks, Deloitte (2023) \\nholds that AI can automate and augment \\nadministrative and problem-solving tasks in \\nall types of jobs. For example, in cognitive \\njobs (e.g., accounting or data analysis), in \\nsocial jobs (e.g., sales), or physical jobs (e.g., \\nplumbers or factory work). It is important \\nto recognise, in any case, that projections \\nare based on technical feasibility, available \\ninfrastructure, organisational capabilities or'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper0.pdf', 'page': 7}, page_content='are based on technical feasibility, available \\ninfrastructure, organisational capabilities or \\nincentives to implement AI at work.\\nIn general, technology can be a crucial tool \\nfor welfare progress, if properly channelled. \\nSimply demonising technology has proved \\nto be the wrong approach. AI can help bring \\nabout solutions to fundamental labour and \\nsocial issues such as those linked to access \\nto healthcare, education, training or access \\nto social protection. It does not have to be a \\nbinary choice of whether to use AI or not; this \\nis a false dichotomy. \\nFurthermore, AI and algorithms are \\nparticularly useful for optimising efficiency, \\nincluding in workforce management. \\nEmployers already see such applications \\nbeing tested in environments such as \\nwarehouses, distribution, or delivery. AI for \\nmanaging worker assignments is also useful. \\nHowever, organisations should ensure this \\nuse of AI is done in a responsible way, with \\nrespect for workers’ free choice of completing'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper0.pdf', 'page': 7}, page_content='use of AI is done in a responsible way, with \\nrespect for workers’ free choice of completing \\nor improving a task and should, for example, \\nnot lead to overly burdensome workloads \\nfor workers. This can subsequently increase \\nthe productivity of organisations as well. \\nAI can help minimise or eliminate routine \\nor repetitive tasks. In some instances, \\npolicymakers see the use of AI to manage'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper0.pdf', 'page': 8}, page_content='9\\nassignments as a factor contributing to \\nsatisfactory or fulfilling work. Businesses \\nshould engage in conversations with \\ngovernments about when and where AI \\ncan help improve or contribute to solving \\nfundamental labour and social problems.\\n \\nMore details on data privacy and data \\nprotection can be found below.\\n5. How is AI changing the demand for \\nskills in the labour market?\\nHistorically, computers have had difficulties \\nperforming tasks that humans can easily \\ncomplete (e.g., talking or perceiving), \\nwhile excelling at tasks that involve logic \\nand calculation (Goel and Davies, 2011). \\nNevertheless, in recent years generative \\nAI has rapidly accelerated progress in the \\ntechnical capabilities of computers to mimic \\nhuman characteristics. Whereas in 2017 \\nMcKinsey had predicted that skills such \\nas coordination with others, creativity and \\nproblem-solving were going to be mastered \\nby computers by 2030 or later. In 2023 \\n(post-generative AI developments) McKinsey'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper0.pdf', 'page': 8}, page_content='by computers by 2030 or later. In 2023 \\n(post-generative AI developments) McKinsey \\nestimated that by 2030, technology will \\ncertainly excel at those and several other \\ncapacities, such as natural language \\nunderstanding, but with the exception of \\nsocial skills (McKinsey & Company, 2023). \\nTo be sure, this does not necessarily imply \\nthat human work will be replaced; rather, it \\nmeans that employers and employees must \\nhave the necessary skills to use AI tools in \\ntheir favour and augment or strengthen \\ntheir own capabilities.\\nThe need for upskilling relates, first, to \\ninvesting in digital skills at different levels: \\nbasic (e.g., accessing computers and \\nsmartphones), intermediate (e.g., job-\\nspecific abilities with dedicated software), \\nand advanced (e.g., programming) (ITU, \\n2021). In relation to advanced digital \\ncapacities, the demand for AI skills (i.e., \\ntechnical abilities such as software \\nengineering or data analysis) has grown \\nsignificantly in recent times. Between 2022'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper0.pdf', 'page': 8}, page_content='engineering or data analysis) has grown \\nsignificantly in recent times. Between 2022 \\nand 2023, job applications requiring AI skills \\nincreased by 15 per cent in Brazil and 19 \\nper cent in United States (LinkedIn, 2023, p. 7). On the other hand, demand for social \\nand emotional skills (e.g., collaboration, \\nconflict resolution, emotional intelligence) \\nis also expected to increase in the near \\nfuture (Strietska-Ilina and Chun, 2021). \\nCertainly, there is awareness in the business \\ncommunity about the upskilling imperative: \\naccording to a PwC (2024) global CEO survey, \\n69 per cent of CEOs think that generative AI \\nwill ultimately require most of their workforce \\nto develop new skills.\\nNew employment challenges and \\nopportunities in algorithmic management can \\nbe found below. \\n6. How is AI making work more \\nproductive?\\nLabour productivity can be defined as \\nthe average economic output that each \\nindividual worker can produce in a certain \\namount of time. Its levels depend on'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper0.pdf', 'page': 8}, page_content='individual worker can produce in a certain \\namount of time. Its levels depend on \\nthe technologies workers have at their \\ndisposal, their working environment and \\nhuman capital, among other factors (Cazes \\nand Verick, 2012). Evidence suggests that \\ntechnological innovations play a key role in \\nproductivity growth: between 1980 and 2018, \\n40 per cent of variation in labour productivity \\nin emerging markets and developing \\neconomies was due to technological change, \\nand in advanced economies it was about \\n50 per cent (Dieppe, 2021, p. 365). The PwC \\nGlobal CEO Survey from 2024 shows that \\n64 per cent of CEOs expect generative AI to \\nincrease the efficiency of their employees’ \\ntime at work (PwC, 2024).\\n \\nAI is expected to have a similar impact in \\nmost industries. As an example, a global \\nstudy from Massachusetts Institute of \\nTechnology compared workers in customer \\nsupport using an AI-powered chatbot with \\nothers not using it (Brynjolfsson, Li and'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper0.pdf', 'page': 8}, page_content='support using an AI-powered chatbot with \\nothers not using it (Brynjolfsson, Li and \\nRaymond, 2023). The study concluded that, \\non average, the former resolved 14 per \\ncent more customer issues than the latter. \\nThis benefit was particularly significant for \\nlow-skilled and new workers, who could \\nhandle 35 per cent more cases than those \\nnot using the chatbot. At an aggregate level, \\nestimates suggest that AI could boost global'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper0.pdf', 'page': 9}, page_content='10\\nproductivity with an annual increase from \\n0.2 per cent to 3.3 per cent, depending on \\ntechnology adoption rates (McKinsey & \\nCompany, 2023, p. 44). Productivity growth, \\na Goldman Sachs report indicates, will be \\nmore noticeable in advanced economies \\ndue precisely to the wider adoption of AI \\nand also because of lower productivity \\ngrowth in these countries. For example, for \\na 10-year period, it is projected that Japan’s \\nproductivity should grow around 1.5 per \\ncent annually, whereas in India It would be \\n0.7 per cent and in Colombia 1.1 per cent \\n(Hatzius et al., 2023).\\n7. How is AI affecting the quality of jobs? \\nGiven that AI is a general-purpose \\ntechnology, its potential implications \\nfor decent work and job quality can be \\nboth positive and negative. Research has \\noften echoed a more pessimistic view, \\nsuggesting that the use of AI in ”algorithmic \\nmanagement” might raise concerns on data \\nprotection, privacy and surveillance (OECD \\n2023), While this form of management'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper0.pdf', 'page': 9}, page_content='protection, privacy and surveillance (OECD \\n2023), While this form of management \\ncan even have counterproductive \\nimplications for employers (Giermindl et \\nal., 2022), there is also evidence that “job \\nquality improvements associated with \\nAI – reductions in tedium, greater worker \\nengagement, and improved physical safety \\nmay be its strongest endorsement from a \\nworker perspective” (Lane, Williams and \\nBroecke, 2023, p. 12). \\nFor instance, in China, there is use of \\nmachine learning methods to predict and \\nprevent accidents in the construction \\nsector, based on data about scenarios, \\nequipment and environment (Luo et al., \\n2023). Companies in OECD countries are \\nalso adopting AI tools to automate tedious \\nwork, leading to “greater enjoyment on \\nthe job” and a greater sense of autonomy \\n(OECD, 2023). Likewise, 55 per cent of larger \\ncompanies worldwide that use AI do so for \\nautomating repetitive tasks (IBM, 2023). \\nLikewise, AI-based virtual trainers, such'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper0.pdf', 'page': 9}, page_content='automating repetitive tasks (IBM, 2023). \\nLikewise, AI-based virtual trainers, such \\nas applications, can personalise training \\nneeds, tailoring the learning process to \\neach individual worker, thus improving their \\nexperience and skills acquisition (Chen, 2023). In other words, AI can be utilised \\nto improve the working environment and \\ngenerate better labour conditions. \\n8. How are organisations and companies \\nresponding to the development of AI?\\nAccording to the IBM Global Adoption \\nIndex 2023, approximately 42 per cent of \\nenterprise-scale businesses (with more \\nthan 1,000 workers) say they have actively \\nimplemented AI in their operations, while \\n40 per cent more are still researching or \\ntesting AI (IBM, 2023). Adoption rates vary by \\ncountry: IBM also reports that in China, 50 per \\ncent of enterprises are actively employing AI, \\nin India 59 per cent and in Latin America 47 \\nper cent, while larger European economies \\nare still in the exploration phase of AI usage'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper0.pdf', 'page': 9}, page_content='per cent, while larger European economies \\nare still in the exploration phase of AI usage \\n(IBM, 2023). Up-to-date data about adoption \\nin small and medium enterprises (SMEs) in \\ndeveloping economies is lacking. \\nAnother trend is that large employers \\nare more likely to implement AI: in OECD \\ncountries, around 50 per cent of large \\nmanufacturing companies (with more than \\n500 employees) were using it in 2022, while \\nonly 23 per cent of small employers (20 to 49 \\nworkers) did (Lane, Williams and Broecke, \\n2023). Adoption of AI is expected to be faster \\nin advanced economies, despite the trend \\nmentioned above in relation to emergent \\neconomies, given higher wages and the \\navailability of technology and basic digital \\ninfrastructure (McKinsey & Company, 2023). \\nFurthermore, projections from the World \\nEconomic Forum’s Future of Jobs Survey \\n(2023) suggests that by 2027, 74.9 per cent \\nof companies globally will have adopted AI. \\nAdditionally, 59 per cent of these companies'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper0.pdf', 'page': 9}, page_content='of companies globally will have adopted AI. \\nAdditionally, 59 per cent of these companies \\npredict that big data and AI will grow in \\nsignificance within their business strategies \\n(WEF, 2023a, pp. 24, 46).\\n9. How is the business ecosystem changing \\ndue to AI?\\nThe transition towards more digitalised \\nbusiness ecosystems is intensifying \\ncompetition for companies, with a \\nproliferation of competitors, industries, and \\ncommercial models available (Calderon-'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper0.pdf', 'page': 10}, page_content='11\\nMonge and Ribeiro-Soriano, 2023). \\nAccording to a PwC global survey, 68 per \\ncent of CEOs believe that “generative AI \\nwill increase competitive intensity in my \\nindustry” (PwC, 2024). In this context, AI is \\na significant resource, especially for SMEs \\nwhich necessitate efficient strategies to \\nremain competitive (Kraus et al., 2021). \\nAs noted by Drydakis (2022, p. 1224), AI \\napplications can be of great value as they \\n”enable SMEs to find new opportunities \\n(sensing capabilities), exploit them (seizing \\ncapabilities) and change operational \\nprocesses (transforming capabilities)” . \\nRegarding specific applications, it is \\nanticipated that companies will utilise AI \\nacross various domains such as process \\noptimisation, customer screening, product and service innovations, and demand \\nforecasting (Lu et al., 2022). AI-enabled tools \\nare offering valuable solutions to a series of \\naspects that provide a competitive advantage \\nto businesses. In relation to logistic barriers'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper0.pdf', 'page': 10}, page_content='aspects that provide a competitive advantage \\nto businesses. In relation to logistic barriers \\nand issues in supply chain management, big \\ndata analytics can mitigate risk and support \\nknowledge sharing (Zamani et al., 2023). In \\norganisational operations, AI applications \\nallow cross-domain knowledge sharing to \\nmaximise the triangulation of data within and \\nwith other companies (Enholm et al., 2022). \\nIn marketing and sales, AI is used at present \\nfor automating e-commerce processes and \\nfor customer screening and support via \\nchatbots (Davenport et al., 2020). AI improves \\nservice offerings, customer experiences and \\nwork efficiency.'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper0.pdf', 'page': 11}, page_content='12\\n10. How is AI being used for hiring \\nemployees?\\nDigital recruiting has gone through different \\nphases since the growth of computer \\nuse in the 1990s.  Initially, it revolved \\naround websites aggregating job offers, \\nwhich expanded from national to global \\nplatforms such as LinkedIn. With the vast \\nnumber of candidates and offers on these \\nplatforms, recruiters have increasingly \\nturned to AI since the 2010s to narrow down \\nopportunities (Black and Van Esch, 2020).\\n \\nAs of 2023, 41 per cent of large enterprises \\nin the world were deploying AI to enhance \\nrecruiting and human resources (HR) \\nprocesses (IBM, 2023). Evidence suggests \\nthat HR managers recognise both the \\nadvantages and drawbacks of AI usage. On \\none hand, it enables decision-makers to \\naccess a larger pool of candidates, which \\ncan be assessed and ranked in a more \\nunbiased manner compared to analogue \\nmethods. On the other hand, concerns \\narise regarding data validity and ethical'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper0.pdf', 'page': 11}, page_content='methods. On the other hand, concerns \\narise regarding data validity and ethical \\nconsiderations in candidate data mining \\n(Radonjić, Duarte and Pereira, 2022; Vrontis \\net al., 2022). \\nSeveral tools have been developed to \\nfacilitate hiring processes. As Gupta and \\nMishra (2022) report, there are AI tools \\nthat pre-assess candidates (e.g., Brazen), \\nscreen large numbers of candidate profiles \\n(e.g., Mya), collect feedback from assessors \\nin different stages of the process (e.g., \\nOlivia) and provide questionnaires and \\ntests (e.g., Pymetrics). Additionally, web-\\nscraping applications that infer candidates’ \\ncharacteristics based on their social media \\nprofiles have also been developing over \\nthe past decade, raising questions about \\nthe ethical implications of AI in recruitment \\n(Dattner et al., 2019). \\nIn summary, the literature emphasises \\nthe usefulness of AI in processing large \\namounts of data, while also highlighting IV . Trends in AI and Labour Management'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper0.pdf', 'page': 11}, page_content='amounts of data, while also highlighting IV . Trends in AI and Labour Management \\nthe risks that may arise from such practices. \\nThe possibilities that AI could bring in terms \\nof labour mobility - increasing the ability to \\nhire personnel based in other countries or \\nwho speak different languages - are another \\npromising area to explore through empirical \\nresearch.\\n11. How is AI being used for performance \\nevaluation and reward systems?\\nThe utilisation of AI in performance \\nmanagement is spreading fast. According \\nto a global survey of managers, 34 per \\ncent of organisations are using AI, such as \\nChat-GPT , to develop new key performance \\nindicators. Remarkably, 90 per cent of these \\norganisations have reported improvements \\nin their indicators as a direct result of \\nemploying AI (Schrage et al., 2024). In \\nrelation to indicator monitoring, AI can be \\ndeployed for descriptive, predictive and \\nprescriptive purposes (Leicht-Deobald et \\nal., 2019). Concerning labour management,'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper0.pdf', 'page': 11}, page_content='prescriptive purposes (Leicht-Deobald et \\nal., 2019). Concerning labour management, \\nAI can enhance performance monitoring \\nin two ways. Firstly, it can provide more \\npersonalised assessments and benchmarks \\nbased on individual historical data and \\ncontextual factors. Secondly, it can facilitate \\ncomparisons across workers through metrics \\nand dashboards (Nyathani, 2023). AI-based \\napplications abound: some help managers \\nallocate tasks and monitor engagement, \\nwhile others allow workers access to HR \\nservices via chatbots.2 \\nBias in performance monitoring is also \\nanother critical aspect to consider. For \\ninstance, Hunkenshroer and Luetge (2022) \\nprovide an example of an algorithm that \\nbenchmarked top performers in a large \\ncompany, the majority of whom were \\nmales, thus penalising females in future \\nassessment criteria. This profiling or undue \\ndiscrimination should be carefully avoided. \\nAnd instead, algorithms should aim to \\nimprove services, improve efficiency (time'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper0.pdf', 'page': 11}, page_content='And instead, algorithms should aim to \\nimprove services, improve efficiency (time \\nspent working) and productivity. On this \\npoint, this should be made possible without \\n2 For a list of examples, see: https://www.springworks.in/blog/ai-tools-for-hr/'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper0.pdf', 'page': 12}, page_content='13\\nany parties infringing intellectual property \\nrights such as accessing source codes, \\nwhich are of importance to companies.\\n12. How is AI being used for conflict \\nmanagement in companies?\\nThe reliance on AI for conflict management \\nand resolution is another area of significant \\ndevelopment in AI research. It can be \\nutilised for formalising the process of \\nnegotiation, such as offering a platform \\nto present preferences and govern the \\ninteraction between parties, or in mediation \\nactivities where different arguments have \\nto be unpacked (Aydoğan, Baarslag and \\nGerding, 2021). \\nIn recent years, AI tools have been \\ndeveloped in the field of dispute resolution \\n(Alessa, 2022). Smartsettle ONE is an \\nexample, a tool which uses a “blind-bid \\nmechanism” to settle legal disputes and \\nhold negotiation sessions, reducing costs on \\nlawyers to reach agreements for the parties \\ninvolved (Financial Times, 2019). There \\nis exploratory research on AI-mediated-'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper0.pdf', 'page': 12}, page_content='involved (Financial Times, 2019). There \\nis exploratory research on AI-mediated-\\nconversation, which aims to perceive \\ndisagreements and propose resolutions, \\nbut its application in the workplace has \\nnot been extensively studied (Hohenstein \\nand Jung, 2020). Even though systems of \\nonline dispute resolution have improved \\nsince the 2000s -for example, through virtual \\nmediation rooms or blind bidding systems \\n(Zeleznikow, 2021) - their expansion in \\nbusinesses worldwide remains an area that \\nrequires empirical study. The same can be \\nsaid about the potential of AI for describing \\nand predicting conflicts in the workplace.\\n13. How is AI being used for downsizing \\ninitiatives?\\nThe link between AI and downsizing is \\ntwofold: first, it refers to the intentional replacement of human labour by companies, \\nand second, to the utilisation of AI tools \\nto identify redundancies and suggest \\nreductions in labour costs. In relation to the \\nfirst aspect, there is evidence of a reduction'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper0.pdf', 'page': 12}, page_content='reductions in labour costs. In relation to the \\nfirst aspect, there is evidence of a reduction \\nin staff costs by automating tasks with AI. \\nIn OECD countries, by 2022, around 40 per \\ncent of employers had adopted AI, and \\nthis resulted in decreasing labour costs in \\nfinance, and in manufacturing this number \\nwas closer to 50 per cent (Lane, Williams and \\nBroecke, 2023, p. 33). Mirroring this trend, \\nmore than half of workers in both sectors in \\nOECD economies expressed concern in 2022 \\nabout losing their jobs to AI in the next two \\nyears (Lane, Williams and Broecke, 2023, p. \\n46). There is a dearth of comparative research \\nthat examines enterprises in developing \\nnations in relation to this matter. \\nIn terms of the second aspect - deploying AI \\ntools for layoff decisions- there is evidence of \\nuse, but again, there is a lack of comparative \\ndata about businesses in developing and \\nemerging economies. In some advanced \\neconomies, on the other hand, there is broad'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper0.pdf', 'page': 12}, page_content='emerging economies. In some advanced \\neconomies, on the other hand, there is broad \\nuse of AI for this purpose. As an example, \\na Capterra  survey of 300 HR leaders in the \\nUnited States in 2023 showed that in case \\nof an economic recession, 98 per cent of \\nthem would rely on data and algorithms \\nto make layoff decisions, with 35 per cent \\nsaying that they would solely use data-driven \\nrecommendations (Westfall, 2023). The study \\nalso remarks that the quality and accuracy of \\ncompanies’ data, for example on employee \\nskills or performance reviews, is crucial to \\nensure fairness and efficiency in HR processes.'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper0.pdf', 'page': 13}, page_content='14\\n14. What AI policies have been developed at the international level?\\nThe policy response to AI in global governance during the last decade has primarily involved \\nthe elaboration of normative frameworks and principles that governments and companies \\ncan adapt to their own AI strategies (Silva 2022). The United Nations has created a High-Level \\nAdvisory Body that will deliver recommendations on the international governance of AI by \\nmid-2024.3 Other relevant international initiatives are:\\nIn regional governance, different organisations have proposed soft-law strategies for AI policy, \\nwith the common characteristic that all of them have embraced the terminology of a “human-\\ncentric” governance approach, also with a focus on the economic value of AI development. \\nFor instance, ASEAN (2024) published guidelines for AI governance in member countries in \\nearly 2024; in 2023, Latin America and the Caribbean, governments elaborated the Santiago'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper0.pdf', 'page': 13}, page_content='early 2024; in 2023, Latin America and the Caribbean, governments elaborated the Santiago \\nDeclaration on ethics of AI (LAC High Level Summit, 2023); the African Union, on its part, is \\npreparing a Continental AI Strategy (Musoni, 2024). V . Policy Challenges and Responses on AI at Work\\n•   ILO Centenary Declaration for the Future of Work (2019): promotes developing \\na human-centred approach that focuses on strengthening people’s capacities, \\nreinforcing the institutions of work and promoting sustained, inclusive and \\nsustainable economic growth and decent work.\\n•   OECD AI Principles (2019): supports human-centred values like respecting the rule \\nof law, human rights, and democratic values throughout the AI lifecycle, aiming to \\npromote inclusive growth and transparent AI development.\\n•   UNESCO Recommendation on AI (2021): emphasises the significance of human \\nsupervision of AI systems, and that policymakers should work alongside'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper0.pdf', 'page': 13}, page_content='supervision of AI systems, and that policymakers should work alongside \\nrepresentatives from the private sector, civil society, unions and other stakeholders \\nfor a fair transition.\\n•   G7 Hiroshima AI International Guiding Principles and Code of Conduct (2023): \\npromotes the safe and responsible development of AI systems through risk \\nmitigation, transparency, governance, security, research prioritisation, and adoption \\nof standards.\\n3 See: https://www.un.org/techenvoy/ai-advisory-body . The UN General Assembly, indicating the direction \\nwhere the Advisory Body might go in terms of AI governance, adopted a resolution in March 2023 that “called \\non all Member States and stakeholders ‘to refrain from or cease the use of artificial intelligence systems that are \\nimpossible to operate in compliance with international human rights law or that pose undue risks to the enjoyment \\nof human rights’” (UN 2024).'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper0.pdf', 'page': 14}, page_content='15\\nSome areas need to be thoroughly \\nanalysed and considered to release all the \\npotentiality of AI in the World of work:\\na. Job losses and job creation. It is \\nlikely that AI, as can be expected with any \\ndisruptive technological change, will bring \\nabout job losses and job creation. The key \\npolicy challenge is to ensure successful \\ntransitional stories of job and income \\nopportunities for more individuals globally. \\nEffective transitions mean that there is a \\nneed to have open and dynamic labour \\nmarkets. It also means that there is a need \\nfor efficient and effective educational and \\nlifelong learning systems to respond to \\ncurrent and future skill needs. Enhancing \\na “learnability” attitude (i.e. the capacity \\nto learn quickly), will be more crucial than \\never, as well as efficient labour market \\ninstitutions facilitating the shift of skills \\ndevelopment needs. Skills are both \\nchallenged and augmented by AI, and \\n“Meta-Learning” (Learning how to learn) is'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper0.pdf', 'page': 14}, page_content='challenged and augmented by AI, and \\n“Meta-Learning” (Learning how to learn) is \\nmore critical than ever (Fadel, 2024).\\nb. Algorithmic management. Policymakers \\nare concerned with potential abusive \\nbehaviour when designing, developing \\nor launching algorithms for the purposes \\nof work-related monitoring systems. \\nThese systems are meant to promote \\nproductivity increases and even enhance \\nwork-life balance. Some analysts warn \\nabout the need to prevent inappropriate \\ndiscrimination, the need to comply with \\nworking time regulations, and the need to \\nbalance productivity with monitoring and \\ndecent working conditions. Some solutions \\nare already in place to settle an appropriate \\nalgorithm management, and this will likely \\nbe an area for policy action. On this point, \\nmaintaining confidentiality in the algorithm \\nformulas is essential to preserve intellectual \\nproperty rights, with some degree of \\ntransparency to be implemented. c. Cybersecurity at the workplace'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper0.pdf', 'page': 14}, page_content='transparency to be implemented. c. Cybersecurity at the workplace \\nand workers’ data. With AI expanding, \\ncybersecurity and data management at the \\nworkplace have become a more challenging \\nand relevant area of potential policy action. \\nThere will likely be a need to avoid or \\nmitigate massive AI attacks on sensitive \\ndata affecting workers’ privacy or Human \\nResources’ confidential information. This \\npoint is also linked to how AI uses workers’ \\nprivate data to guide advice on Human \\nResources policies.\\nd. Misinformation at the workplace. As \\nmentioned above, the wrong use of AI can \\nalso lead to misinformation affecting the \\nworkplace (fake certificates, fake voices, \\nfake information on workers’ behaviours or \\nprivate lives). Again, this represents a growing \\narea of policy action.\\n4 The EU AI Act distinguishes between “minimal risk” systems (e.g., recommender systems or spam filters), “high'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper0.pdf', 'page': 14}, page_content='risk” (e.g., critical infrastructures; medical devices; recruitment systems), “unacceptable risk” (e.g., social scoring, \\npredictive policing, emotion recognition), and “specific transparency risk” (e.g., chatbots or deepfakes). Among \\nthese, minimal risk systems will be allowed to operate. High-risk ones will need to specify risk-mitigation systems \\nto regulators. Unacceptable risk systems will not be allowed to operate. Lastly, specific transparency systems will \\nrequire that contents have an explicit recognition that they have been generated by an AI. Non-compliance will be \\nfined with a 7 per cent of total global annual turnover, and supply of incorrect or misleading information will entail a \\n1.5 per cent fine. Guidance mentions that in principle SMEs would have lower fines than larger companies. For more \\ninformation, see European Commission (2023a).'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper0.pdf', 'page': 15}, page_content='16\\n15. What does the European Union’s AI \\nAct entail for business?\\nIn December 2023, the European Union \\n(EU) reached an agreement with members \\non the first hard-law regulation: the EU AI \\nAct. The Act takes a risk-based approach \\nto regulation by classifying AI systems \\naccording to their risk profile.4 In terms of its \\nimplications for businesses: \\nAccordingly, EU countries, in collaboration \\nwith new European AI Office, will be in \\ncharge of assessing AI applications. Some \\nof the AI tools that are being utilised by \\ncompanies at present could be subject to \\nscrutiny as a result: for instance, emotion \\nrecognition in the workplace is deemed \\n“unacceptable” by the Act, AI-powered \\nrecruitment techniques could be classified \\nas “high risk” , and generative AIs such as \\nChat-GPT , might not face major constraints \\ninsofar as they can ensure transparency for \\nusers (European Commission, 2023b). The \\ntimeline of the AI Act implies that 6 months'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper0.pdf', 'page': 15}, page_content='users (European Commission, 2023b). The \\ntimeline of the AI Act implies that 6 months \\nafter entering into force, EU states must \\nstart phasing out “prohibited systems” and \\nafter 24 months, “all rules would become \\napplicable” , including regulation of high-risk \\nsystems (European Commission, 2023a).\\n16. What are the policy responses and \\npriorities at the domestic level?\\nThe OECD AI Policy Observatory serves \\nas a vital data source for analysing \\nnational AI policies across most countries \\nglobally.5 Most initiatives have consisted \\nin the creation of national strategies for AI \\ndevelopment, in evaluating regulations and \\ngovernance instruments. Firms have been \\nan important target group for government \\ninitiatives. Among the 407 initiatives the \\nOECD reports about, 115 have been focused \\non SMEs, 43 on multinational companies, 40 \\non large firms and 25 on micro-enterprises.6 \\nWithin the large variety of initiatives that can \\nbe found globally, national AI governance'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper0.pdf', 'page': 15}, page_content='Within the large variety of initiatives that can \\nbe found globally, national AI governance \\ncan be broadly divided into three areas:1.  Creation of institutional capacity: new \\ninstitutions have been created to unify \\ngovernment efforts and initiatives related to \\nAI and to provide advice for policymakers. \\nThe institutional landscape of AI varies from \\ncountry to country (Radu, 2021).\\n2.   Stimulating AI adoption: governments \\nare promoting adoption in both the public \\nand private sectors. Direct government \\nsupport includes providing grants for AI \\nproject development in companies and \\nfunding for AI startups. Indirect support \\nencompasses policies such as skills \\nstrategies aimed at promoting AI skills \\nwithin education systems, as well as the \\nutilisation of tax credits related to R&D \\ninvestment in companies (Milanez, 2023). \\nAdditionally, government-funded R&D \\ninvestment has promoted national AI \\nresearch centres and networks (Galindo, \\nPerset and Sheeka, 2021).'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper0.pdf', 'page': 15}, page_content='research centres and networks (Galindo, \\nPerset and Sheeka, 2021).\\n3.   AI ethics and transparency: governments \\nare aiming to balance the potential benefits \\nof AI with consideration of issues that \\nmight undermine the trustworthiness of \\nAI. The development of policies in that \\nline has concentrated on creating new \\nethical advice bodies and elaborating \\nnormative frameworks that can be used as \\nguidelines for AI adoption in each country, \\nwhich tend to be voluntary in terms of \\nenforcement (OECD, 2024). Another focal \\npoint of initiatives has been data protection \\nlegislation; most countries already have \\nregulations in place, but some have created \\nnew norms to address digital privacy \\nconcerns (UNCTAD, 2021).\\n5 See: https://oecd.ai/en/dashboards/overview\\n6 As of February 2024. See: https://oecd.ai/en/dashboards/overview/target'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper0.pdf', 'page': 16}, page_content='17\\nRecommendations for Employers’ Organisations and Companies\\nThe priorities of companies and employer organisations regarding the emergence of AI can \\nbe categorised into two levels. Firstly, individual organisations need to take proactive steps \\nto leverage the benefits of this technology while mitigating various risks. Secondly, business \\nadvocates must concentrate their efforts on promoting AI adoption that enhances productivity \\nin collaboration with governments.\\nOrganisation-level recommendations:\\n• Promote a culture of innovation: where AI adoption is deemed a feasible option and \\nappropriate governance systems are in place, organisations should encourage a culture \\nof innovation that allows for practical experimentation and learning from successes \\nor failures. This will support strategy execution but also ensure that organisations stay \\ninformed about AI developments and are better prepared to pivot or adapt strategies as \\nneeded.'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper0.pdf', 'page': 16}, page_content='informed about AI developments and are better prepared to pivot or adapt strategies as \\nneeded.\\n• Elaborate an AI strategy for your organisation: AI can improve business performance \\nand innovativeness, but employers need first to elaborate company-specific AI strategies \\nthat serve as a navigation chart in their journey. It can be a similar approach to how \\ncompanies have dealt with technologies in the past (such as when the internet was first \\ndeveloped). At the global level, in 2023 59 per cent of large enterprises had an AI strategy \\nin place, while 32 per cent was developing one, and only 4 per cent did not have any \\n(IBM, 2023, p. 22). Although data on SMEs is still scarce, research suggest that they need \\nto plan ahead on three levels of AI capability: the creation of organisational resources, \\ndata resources and responsible AI governance mechanisms to ensure the efficiency and \\nfairness in their structural changes (Enholm et al., 2022).'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper0.pdf', 'page': 16}, page_content='fairness in their structural changes (Enholm et al., 2022). \\n• Investing in knowledge and skills development: These must be a priority for business \\nin promoting job productivity. Some need to develop an understanding (knowledge), \\nand others will need to be able to apply this in a practical way (skills). An Adecco global \\nsurvey shows that only 46 per cent of workers were receiving guidance on how to use AI \\nin their tasks in 2023, indicating that this remains a significant challenge for business AI \\nstrategies (Adecco Group 2023). AI can act as a co-pilot where it can assist humans to be \\nin control. AI is created by people, for people. \\n• Evaluate ethical risk assessments of AI tools: given the importance of ethical risk \\nin public and policy discourse, companies should approach this dimension with \\nseriousness. This involves assessing issues related to data availability and access, \\nthe internal governance of AI in the workplace, and normative aspects that influence'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper0.pdf', 'page': 16}, page_content='the internal governance of AI in the workplace, and normative aspects that influence \\nemployers’ interactions with workers and customers (Lu et al., 2022). In other \\nwords, “further deliberation is needed to address governance issues such as the \\nhandling of personal information included in AI training data and the disclosure of \\npersonal information in generative AI outputs” (Keidanren 2023). Social dialogue and \\ncollaboration with governments and workers is a viable strategy to face ethical concerns \\nregarding AI adoption, and it can facilitate the introduction of AI innovations and their \\ndesign at work (OECD 2023). \\n• Implement transition programmes: this can be in the form of retraining and \\nredeployment initiatives. VI. Recommendations and Priorities for Employers’ \\nOrganisations and Governments'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper0.pdf', 'page': 17}, page_content='18\\nAdvocacy-level recommendations:\\n• Promote research or the collection of data for SMEs or in developing countries to \\nsupport decision-making, strategy or policy development: as mentioned above, there \\nwere references to gaps in available data for SMEs in developing countries.\\n \\n• Employers can also advocate for sector-specific guidelines, recognising that AI’s value, \\nimpact and risks may vary across sectors.\\n• Promote a smooth transition for AI adoption: as mentioned above, AI has at least three \\neffects on employment: job displacement, augmentation and creation. What matters \\nmost is promoting a smooth transition to minimise net job losses. It can also help move \\nbusinesses and workers from routine to more creative jobs. Transitions mean open \\nand dynamic labour markets. Robust educational and training systems are needed to \\nrespond to real skills needs. This is also linked to having an open mindset to learning'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper0.pdf', 'page': 17}, page_content='respond to real skills needs. This is also linked to having an open mindset to learning \\nand the capacity to learn quickly. Strong institutions can help facilitate the shift of skills \\ndevelopment. Otherwise, countries and companies will face massive disruptions in the \\nlabour market, perhaps more than ever.\\n• Promote policies that address barriers to AI adoption: currently, the most prominent \\nobstacles to AI development faced by employers are linked to a shortage of AI skills and \\nexpertise, an inability to manage complex datasets, and integrate and scale them within \\norganisational operations (IBM, 2023). Employers can advocate for government policies \\nthrough direct and indirect support initiatives. In particular, reskilling and upskilling \\nprogrammes are the type of measures that most employers see as beneficial to increase \\ntheir capacity for technological innovation (WEF, 2023a). At the same time, supporting'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper0.pdf', 'page': 17}, page_content='their capacity for technological innovation (WEF, 2023a). At the same time, supporting \\nsocial safety nets might help to make this transition more socially sustainable \\n(Cazzaniga et al., 2024). Policymakers should not stifle innovation as AI and other forms \\nof technology can assist micro, small and medium sized companies, offer business \\nand economic opportunities for entrepreneurs and those in the world of work. New \\nregulations are not necessarily the panacea to resolve issues, it is a matter to embedding \\na culture of ethical awareness and a mindset of adaptation.  \\n• Establish partnerships with stakeholders to support AI adoption: the diffusion \\nof innovations in national economies will probably come from a synergy of actors \\nsupporting AI implementation. Partnerships with international organisations, \\ndevelopment agencies, experts, civil society and workers’ organisations might catalyse \\nthis process. For instance, university collaborations can help establish connections'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper0.pdf', 'page': 17}, page_content='this process. For instance, university collaborations can help establish connections \\nbetween governments, academic research and industry, facilitating knowledge sharing \\nand training opportunities for companies and also increasing AI literacy in the business \\necosystem (Milanez, 2023). This could mean a new set of partnerships unseen before.\\nPolicy Recommendations for Governments\\n• General risk mitigation should be given more prominence: particularly in respect of \\nconducting periodic risk assessments and developing appropriate contingency plans, \\nincluding investments in suitable cybersecurity infrastructure. At the government level, \\npromoting investments in cybersecurity infrastructure, particularly for SMEs, may \\nbe a useful consideration. An example can be observed in Trinidad and Tobago: the \\ngovernment introduced a Cybersecurity Investment Tax Allowance in January 2024, \\nwhich offers a tax deduction of up to $500,000 TTD (approx. 74,000 USD) to businesses'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper0.pdf', 'page': 17}, page_content='which offers a tax deduction of up to $500,000 TTD (approx. 74,000 USD) to businesses \\nthat invest in eligible cybersecurity software and network security monitoring \\nequipment. Issues such as data protection and security of workers’ data and sensitive'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper0.pdf', 'page': 18}, page_content='19\\ncompany data (HR and financial), and use of IT devices, equipment, software and \\nservices should be reviewed and monitored. There are various cases where it is easy to \\nimpersonate a person at the workplace.\\n• Governments also have a responsibility, in terms of facilitating digital literacy \\nprogrammes across all levels of society . This will ensure that its citizens are better \\nprepared for the realities of working in an AI-based workplace or economy.\\n• Providing unemployment relief support (social protection) or other types of retraining \\nor employment programmes for workers who are in transition.'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper0.pdf', 'page': 19}, page_content='20\\nVII. References\\nAcemoglu, D. and Autor, D. (2010) Skills, Tasks and Technologies: Implications for Employment \\nand Earnings. w16082. Cambridge, MA: National Bureau of Economic Research, p. w16082. \\nAvailable at: https://doi.org/10.3386/w16082.\\nAdecco Group (2023) ‘What’s working? Navigating the AI revolution and the shifting future of \\nwork’ . Available at: https://www.adeccogroup.com/Global-Workforce-of-the-Future-\\nresearch-2023\\nAlessa, H. (2022) ‘The role of Artificial Intelligence in Online Dispute Resolution: A brief and \\ncritical overview’ , Information & Communications Technology Law, 31(3), pp. 319–342. Available \\nat: https://doi.org/10.1080/13600834.2022.2088060 .\\nASEAN (2024) ‘ASEAN Guide on AI Governance and Ethics’ . Available at: https://asean.org/\\nbook/asean-guide-on-ai-governance-and-ethics/\\nAydoğan, R., Baarslag, T . and Gerding, E. (2021) ‘Artificial Intelligence Techniques for Conflict'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper0.pdf', 'page': 19}, page_content='Aydoğan, R., Baarslag, T . and Gerding, E. (2021) ‘Artificial Intelligence Techniques for Conflict \\nResolution’ , Group Decision and Negotiation, 30(4), pp. 879–883. Available at: https://doi.\\norg/10.1007/s10726-021-09738-x.\\nBlack, J.S. and Van Esch, P . (2020) ‘AI-enabled recruiting: What is it and how should a manager \\nuse it?’ , Business Horizons, 63(2), pp. 215–226. Available at: https://doi.org/10.1016/j.\\nbushor.2019.12.001.\\nBrynjolfsson, E., Li, D. and Raymond, L. (2023) Generative AI at Work. w31161. Cambridge, MA: \\nNational Bureau of Economic Research, p. w31161. Available at: https://doi.org/10.3386/\\nw31161.\\nBuchanan, B. (2005) ‘A (Very) Brief History of Artificial Intelligence’ , AI Magazine, 26(4). Available \\nat: https://doi.org/10.1609/aimag.v26i4.1848.\\nCalderon-Monge, E. and Ribeiro-Soriano, D. (2023) ‘The role of digitalization in business and \\nmanagement: a systematic literature review’ , Review of Managerial Science [Preprint]. Available'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper0.pdf', 'page': 19}, page_content='management: a systematic literature review’ , Review of Managerial Science [Preprint]. Available \\nat: https://doi.org/10.1007/s11846-023-00647-8.\\nCazes, S. and Verick, S. (eds) (2012) Perspectives on labour economics for development. Geneva: \\nInternational Labour Office.\\nCazzaniga, M. et al. (2024) ‘Gen-AI: Artificial Intelligence and the Future of Work’ , IMF Staff \\nDiscussion Notes, 2024(001), p. 1. Available at: https://doi.org/10.5089/9798400262548.006.\\nChen, Z. (2023) ‘Artificial Intelligence-Virtual Trainer: Innovative Didactics Aimed at \\nPersonalized Training Needs’ , Journal of the Knowledge Economy, 14(2), pp. 2007–2025. \\nAvailable at: https://doi.org/10.1007/s13132-022-00985-0.\\nDattner, B. et al. (2019) ‘The Legal and Ethical Implications of Using AI in Hiring’ , Harvard \\nBusiness Review, 25 April. Available at: https://hbr.org/2019/04/the-legal-and-ethical-\\nimplications-of-using-ai-in-hiring.'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper0.pdf', 'page': 19}, page_content='implications-of-using-ai-in-hiring.\\nDavenport, T . et al. (2020) ‘How artificial intelligence will change the future of marketing’ ,'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper0.pdf', 'page': 20}, page_content='21\\nJournal of the Academy of Marketing Science, 48(1), pp. 24–42. Available at: https://doi.\\norg/10.1007/s11747-019-00696-0.\\nDeloitte (2023) ‘Generative AI and the future of work’ . Deloitte. Available at: https://www2.\\ndeloitte.com/us/en/pages/consulting/articles/generative-ai-and-the-future-of-work.\\nhtml.\\nDieppe, A. (ed.) (2021) Global productivity: trends, drivers, and policies. Washington, DC: World \\nBank Group.\\nEconomist (2024) ‘Many AI researchers think fakes will become undetectable’ . Available at: \\nhttps://www.economist.com/science-and-technology/2024/01/17/many-ai-\\nresearchers-think-fakes-will-become-undetectable\\nEnholm, I.M. et al. (2022) ‘Artificial Intelligence and Business Value: a Literature Review’ , \\nInformation Systems Frontiers, 24(5), pp. 1709–1734. Available at: https://doi.org/10.1007/\\ns10796-021-10186-w.\\nEuropean Commission (2023a) ‘Artificial intelligence- questions and answers’ . Available at:'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper0.pdf', 'page': 20}, page_content='European Commission (2023a) ‘Artificial intelligence- questions and answers’ . Available at: \\nhttps://ec.europa.eu/commission/presscorner/detail/en/QANDA_21_1683.\\nEuropean Commission (2023b) Commission welcomes political agreement on Artificial \\nIntelligence Act. Available at: https://ec.europa.eu/commission/presscorner/detail/en/\\nip_23_6473.\\nFadel, C. et al. (2024) ‘Education for the Age of AI’ . Available at: https://curriculumredesign.\\norg/our-work/education-for-the-age-of-ai/. \\nFinancial Times (2019) ‘Robots and AI threaten to mediate disputes better than lawyers’ , \\n14 August. Available at: https://www.ft.com/content/187525d2-9e6e-11e9-9c06-\\na4640c9feebb.\\nFrank, M.R. et al. (2019) ‘Toward understanding the impact of artificial intelligence on labor’ , \\nProceedings of the National Academy of Sciences, 116(14), pp. 6531–6539. Available at: https://\\ndoi.org/10.1073/pnas.1900949116.\\nFrey, C. and Osborne, M. (2023) Generative AI and the Future of Work: A Reappraisal. Working'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper0.pdf', 'page': 20}, page_content='Frey, C. and Osborne, M. (2023) Generative AI and the Future of Work: A Reappraisal. Working \\nPaper No. 2023. Oxford Martin School.\\nG7 (2023) ‘Hiroshima Process International Code of Conduct for Organizations Developing \\nAdvanced AI Systems’ . G7 2023 Hiroshima Summit.\\nGalindo, L., Perset, K. and Sheeka, F. (2021) An overview of national AI strategies and policies. \\nGoing Digital Toolkit Note 14. Available at: https://goingdigital.oecd.org/data/notes/\\nNo14_ToolkitNote_AIStrategies.pdf\\nGiermindl, L.M. et al. (2022) ‘The dark sides of people analytics: reviewing the perils for \\norganisations and employees’ , European Journal of Information Systems, 31(3), pp. 410–435. \\nAvailable at: https://doi.org/10.1080/0960085X.2021.1927213.\\nGilbert, A. (2023) ‘Reframing Automation - a new model for anticipating risks and impacts. \\nInstitute for the Future of Work (UK). Available at: https://zenodo.org/record/8099822 \\n(Accessed: 18 February 2024).'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper0.pdf', 'page': 21}, page_content='22\\nGmyrek, P ., Berg, J. and Bescond, D. (2023) ‘Generative AI and Jobs: A Global Analysis of \\nPotential Effects on Job Quantity and Quality’ , SSRN Electronic Journal, ILO Working Paper 96. \\nAvailable at: https://doi.org/10.2139/ssrn.4584219.\\nGoel, A.K. and Davies, J. (2011) ‘Artificial Intelligence’ , in R.J. Sternberg and S.B. Kaufman (eds) \\nThe Cambridge Handbook of Intelligence. 1st edn. Cambridge University Press, pp. 468–482. \\nAvailable at: https://doi.org/10.1017/CBO9780511977244.024.\\nGupta, A. and Mishra, M. (2022) ‘Ethical Concerns While Using Artificial Intelligence in \\nRecruitment of Employees’ , Business Ethics and Leadership, 6(2), pp. 6–11. Available at: https://\\ndoi.org/10.21272/bel.6(2).6-11.2022.\\nHatzius, J. et al. (2023) ‘The Potentially Large Effects of Artificial Intelligence on Economic \\nGrowth’ . Goldman Sachs. Available at: https://www.gspublishing.com/content/\\nresearch/en/reports/2023/03/27/d64e052b-0f6e-45d7-967b-d7be35fabd16.html'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper0.pdf', 'page': 21}, page_content='research/en/reports/2023/03/27/d64e052b-0f6e-45d7-967b-d7be35fabd16.html\\nHohenstein, J. and Jung, M. (2020) ‘AI as a moral crumple zone: The effects of AI-mediated \\ncommunication on attribution and trust’ , Computers in Human Behavior, 106, p. 106190. \\nAvailable at: https://doi.org/10.1016/j.chb.2019.106190.\\nHunkenschroer, A.L. and Luetge, C. (2022) ‘Ethics of AI-Enabled Recruiting and Selection: A \\nReview and Research Agenda’ , Journal of Business Ethics, 178(4), pp. 977–1007. Available at: \\nhttps://doi.org/10.1007/s10551-022-05049-6.\\nIBM (2023) ‘Global AI Adoption Index 2023’ . IBM. Available at: https://filecache.mediaroom.\\ncom/mr5mr_ibmspgi/179414/download/IBM%20Global%20AI%20Adoption%20\\nIndex%20Report%20Dec.%202023.pdf.\\nILO (2019) Centenary Declaration for the Future of Work. Geneva: International Labour Office.\\nITU (2021) Digital skills insights 2021. Geneva: International Telecommunication Union.'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper0.pdf', 'page': 21}, page_content='ITU (2021) Digital skills insights 2021. Geneva: International Telecommunication Union.\\nKaplan, A. and Haenlein, M. (2019) ‘Siri, Siri, in my hand: Who’s the fairest in the land? On the \\ninterpretations, illustrations, and implications of artificial intelligence’ , Business Horizons, 62(1), \\npp. 15–25. Available at: https://doi.org/10.1016/j.bushor.2018.08.004.\\nKraus, S. et al. (2021) ‘Digital Transformation: An Overview of the Current State of the \\nArt of Research’ , SAGE Open, 11(3), p. 215824402110475. Available at: https://doi.\\norg/10.1177/21582440211047576.\\nLAC High Level Summit (2023) ‘Declaracion de Santiago. Para promover una inteligencia \\nartificial ética en América Latina y el Caribe’ . Available at: https://minciencia.gob.cl/\\nuploads/filer_public/40/2a/402a35a0-1222-4dab-b090-5c81bbf34237/declaracion_\\nde_santiago.pdf\\nLane, M., Williams, M. and Broecke, S. (2023) The impact of AI on the workplace: Main findings'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper0.pdf', 'page': 21}, page_content='Lane, M., Williams, M. and Broecke, S. (2023) The impact of AI on the workplace: Main findings \\nfrom the OECD AI surveys of employers and workers. OECD Social, Employment and Migration \\nWorking Papers 288. Available at: https://doi.org/10.1787/ea0a0fe1-en.\\nLeicht-Deobald, U. et al. (2019) ‘The Challenges of Algorithm-Based HR Decision-Making for \\nPersonal Integrity’ , Journal of Business Ethics, 160(2), pp. 377–392. Available at: https://doi.\\norg/10.1007/s10551-019-04204-w.'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper0.pdf', 'page': 22}, page_content='23\\nLinkedin (2023) ‘Future of work report. AI at work’ . Available at: https://economicgraph.\\nlinkedin.com/research/future-of-work-report-ai\\nLu, X. et al. (2022) ‘AI-Enabled Opportunities and Transformation Challenges for SMEs in the \\nPost-pandemic Era: A Review and Research Agenda’ , Frontiers in Public Health, 10, p. 885067. \\nAvailable at: https://doi.org/10.3389/fpubh.2022.885067.\\nLuo, X. et al. (2023) ‘Application of machine learning technology for occupational accident \\nseverity prediction in the case of construction collapse accidents’ , Safety Science, 163, p. \\n106138. Available at: https://doi.org/10.1016/j.ssci.2023.106138.\\nMcKinsey & Company (2023) ‘The economic potential of generative AI: The next productivity \\nfrontier’ . McKinsey. Available at: https://www.mckinsey.com/capabilities/mckinsey-\\ndigital/our-insights/the-economic-potential-of-generative-ai-the-next-\\nproductivity-frontier'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper0.pdf', 'page': 22}, page_content='digital/our-insights/the-economic-potential-of-generative-ai-the-next-\\nproductivity-frontier\\nMilanez, A. (2023) The impact of AI on the workplace: Evidence from OECD case studies of AI \\nimplementation. OECD Social, Employment and Migration Working Papers 289. Available \\nat: https://www.oecd.org/publications/the-impact-of-ai-on-the-workplace-\\nevidence-from-oecd-case-studies-of-ai-implementation-2247ce58-en.htm  \\n(Accessed: 19 February 2024).\\nMusoni, M. (2024) ‘Envisioning Africa’s AI governance landscape in 2024’ , ECDPM, January. \\nAvailable at: https://ecdpm.org/work/envisioning-africas-ai-governance-\\nlandscape-2024.\\nNyathani, R. (2023) ‘AI in Performance Management: Redefining Performance Appraisals in the \\nDigital Age’ , Journal of Artificial Intelligence & Cloud Computing, pp. 1–5. Available at: https://\\ndoi.org/10.47363/JAICC/2023(2)134.\\nOECD (2019) ‘OECD AI Principles’ . Available at: https://oecd.ai/en/ai-principles/.'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper0.pdf', 'page': 22}, page_content='OECD (2019) ‘OECD AI Principles’ . Available at: https://oecd.ai/en/ai-principles/.\\nOECD (2023) OECD Employment Outlook 2023: Artificial Intelligence and the Labour Market. \\nAvailable at: https://doi.org/10.1787/08785bba-en.\\nOECD (2024) OECD AI Policy Observatory: Regulatory oversight and ethical advice bodies. \\nAvailable at: https://oecd.ai/en/dashboards/policy-instruments/Regulatory_oversight_\\nand_ethical_advice_bodies.\\nPwC (2024) ‘Thriving in an age of continuous reinvention’ . PwC. Available at: https://www.\\npwc.com/gx/en/issues/c-suite-insights/ceo-survey.html#the-ai-opportunity.\\nRadonjić, A., Duarte, H. and Pereira, N. (2022) ‘Artificial intelligence and HRM: HR \\nmanagers’ perspective on decisiveness and challenges’ , European Management Journal, p. \\nS0263237322000883. Available at: https://doi.org/10.1016/j.emj.2022.07.001.\\nRadu, R. (2021) ‘Steering the governance of artificial intelligence: national strategies in'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper0.pdf', 'page': 22}, page_content='Radu, R. (2021) ‘Steering the governance of artificial intelligence: national strategies in \\nperspective’ , Policy and Society, 40(2), pp. 178–193. Available at: https://doi.org/10.1080/1449\\n4035.2021.1929728.\\nRussell, S. and Norvig, P . (2020) Artificial intelligence: A modern approach. 4. ed. London: \\nPearson.\\nRussell, S.J. (2019) Human compatible: artificial intelligence and the problem of control. New \\nYork. Viking.'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper0.pdf', 'page': 23}, page_content='24\\nShanbhogue, R. (2023). Generative AI holds much promise for businesses. The Economist. \\nAvailable at: https://www.economist.com/the-world-ahead/2023/11/13/generative-ai-\\nholds-much-promise-for-businesses.  \\nSchrage, M. et al. (2024) ‘The Future of Strategic Measurement: Enhancing KPIs with AI’ . MIT \\nSloan Management Review. Available at: https://shop.sloanreview.mit.edu/store/the-\\nfuture-of-strategic-measurement-enhancing-kpis-with-ai.\\nSilva, V. (2022). The Schumpeterian consensus: The new logic of global social policy to face \\ndigital transformation. Journal of Social Policy, pp.1–17. Available at: https://doi.org/10.1017/\\ns0047279422000861.\\n Strietska-Ilina, O. and Chun, H.-K. (2021) Changing demand for skills in digital economies and \\nsocieties: literature review and case studies from low- and middle-income countries. \"Available \\nat: https://www.ilo.org/publications/changing-demand-skills-digital-economies-\\nand-societies-literature-review \".'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper0.pdf', 'page': 23}, page_content='and-societies-literature-review \".\\nUN (2024). General Assembly adopts landmark resolution on artificial intelligence. UN News. \\nAvailable at: https://news.un.org/en/story/2024/03/1147831. \\nUNCTAD (2021) Data Protection and Privacy Legislation Worldwide. Available at: https://\\nunctad.org/page/data-protection-and-privacy-legislation-worldwide.\\nUNESCO (2021) ‘UNESCO Recommendation on the Ethics of AI’ . Available at: https://www.\\nunesco.org/en/articles/recommendation-ethics-artificial-intelligence.\\nVrontis, D. et al. (2022) ‘Artificial intelligence, robotics, advanced technologies and human \\nresource management: a systematic review’ , The International Journal of Human Resource \\nManagement, 33(6), pp. 1237–1266. Available at: https://doi.org/10.1080/09585192.2020.18\\n71398.\\nWamba-Taguimdje, S.-L. et al. (2020) ‘Influence of artificial intelligence (AI) on firm \\nperformance: the business value of AI-based transformation projects’ , Business Process'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper0.pdf', 'page': 23}, page_content='performance: the business value of AI-based transformation projects’ , Business Process \\nManagement Journal, 26(7), pp. 1893–1924. Available at: https://doi.org/10.1108/BPMJ-10-\\n2019-0411.\\nWEF (2023a) ‘Future of jobs report 2023’ . World Economic Forum. Available at: https://www3.\\nweforum.org/docs/WEF_Future_of_Jobs_2023.pdf.\\nWEF (2023b) ‘Jobs of Tomorrow:  Large Language   Models and Jobs’ . World Economic Forum. \\nAvailable at: https://www3.weforum.org/docs/WEF_Jobs_of_Tomorrow_Generative_\\nAI_2023.pdf.\\nWestfall, B. (2023) ‘Algorithms Will Make Critical Talent Decisions in the Next Recession’ . \\nCapterra. Available at: https://www.capterra.com/resources/recession-planning-for-\\nbusinesses/.\\nZamani, E.D. et al. (2023) ‘Artificial intelligence and big data analytics for supply chain \\nresilience: a systematic literature review’ , Annals of Operations Research, 327(2), pp. 605–632. \\nAvailable at: https://doi.org/10.1007/s10479-022-04983-y.'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper0.pdf', 'page': 23}, page_content='Available at: https://doi.org/10.1007/s10479-022-04983-y.\\nZeleznikow, J. (2021) ‘Using Artificial Intelligence to provide Intelligent Dispute Resolution \\nSupport’ , Group Decision and Negotiation, 30(4), pp. 789–812. Available at: https://doi.\\norg/10.1007/s10726-021-09734-1.'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper0.pdf', 'page': 24}, page_content='25\\n© IOE 2024Avenue Louis-Casaï 71 – CH-1216 Genève\\nT +41 22 929 00 00 F +41 22 929 00 01 \\nioe@ioe-emp.com • ioe-emp.org'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper1.pdf', 'page': 0}, page_content='Framework Convention \\non Global AI Challenges\\nAccelerating international cooperation to ensure \\nbeneficial, safe and inclusive AI\\nDuncan Cass-Beggs      \\nStephen Clare      \\nDawn Dimowo      \\nZaheed KaraCIGI Discussion Paper'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper1.pdf', 'page': 1}, page_content='About the Global AI Risks Initiative  \\nThe Global AI Risks Initiative at the Centre for International Governance \\nInnovation was created to advance the international governance that will be \\nneeded to manage global AI risks. The Initiative aims to mobilize the resources, \\ntalent and influence of policy makers, AI researchers, governance experts and \\ncivil society to reduce global risks from advanced AI systems. It seeks to build \\nunderstanding of the importance of global risks from AI and access to workable \\npolicy options to mitigate these risks successfully.  \\n \\nThis discussion paper proposes the development of an international Framework \\nConvention on Global AI Challenges accompanied by specific supporting \\nprotocols to address specific global challenges raised by advanced AI. The \\npaper draws on a wealth of existing research and policy efforts, as well as \\nvaluable discussions and feedback from many quarters. Nevertheless, the'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper1.pdf', 'page': 1}, page_content='valuable discussions and feedback from many quarters. Nevertheless, the \\nrecommendations are preliminary and intended to support further dialogue, \\nreflection and action. The authors welcome feedback, as well as suggested \\nimprovements and collaborations. They may be reached at  \\nglobalairisks@cigionline.org .Credits  \\nExecutive Director, Global AI Risks Initiative Duncan Cass-Beggs  (lead author)  \\nSenior Research Associate, Global AI Risks Initiative Stephen Clare  (lead author)  \\nProgram Manager, Global AI Risks Initiative Dawn Dimowo  \\nSenior Research Associate, Global AI Risks Initiative Zaheed Kara  \\nSenior Publications Editor Jennifer Goyder  \\nPublications Editor Susan Bubak  \\nGraphic Designer Sami Chouhdary\\nCopyright © 2024 by the Centre for International Governance Innovation\\nThe opinions expressed in this publication are those of the authors and do not \\nnecessarily reflect the views of the Centre for International Governance Innovation  \\nor its Board of Directors.'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper1.pdf', 'page': 1}, page_content='or its Board of Directors.\\nFor publications enquiries, please contact publications@cigionline.org.\\nThe text of this work is licensed under CC BY 4.0. To view a copy of this licence, \\nvisit http://creativecommons.org/licenses/by/4.0/. \\nFor reuse or distribution, please include this copyright notice. This work may \\ncontain content (including but not limited to graphics, charts and photographs) \\nused or reproduced under licence or with permission from third parties. \\nPermission to reproduce this content must be obtained from third parties directly.\\nCentre for International Governance Innovation and CIGI are registered \\ntrademarks.\\n67 Erb Street West  \\nWaterloo, ON, Canada N2L 6C2\\nwww.cigionline.org'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper1.pdf', 'page': 2}, page_content='Table of Contents\\n1 Executive Summary\\n3 Introduction\\n5 Global Challenges from Advanced AI\\n9 Current International Cooperation Efforts Are \\nInsufficient for Global AI Challenges\\n11 A Framework Convention on Global AI Challenges\\n14 A Protocol on Global Public Safety and Security \\nRisks from AI (“Protocol on AI Safety”)\\n18 Challenges, Opportunities and Next Steps\\n20 Conclusion'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper1.pdf', 'page': 4}, page_content='1Executive Summary\\nAdvanced artificial intelligence (AI) could be the most powerful technology ever created by \\nhumans,  unleashing explosive growth in cognitive capability that transforms all aspects of society \\nand shapes the future trajectory of civilization. Such a transformation presents unprecedented global \\nchallenges. Humanity must realize and distribute global benefits from AI, address global AI risks and \\nmake globally legitimate and effective decisions about how to govern advanced AI. This will require \\nthe very best of human ingenuity, wisdom and global cooperation over the coming years. \\nFuture developments in AI could bring enormous global benefits,  with the potential to accelerate \\nscientific discovery, spur technological innovation and massively increase prosperity. However, \\nthese benefits cannot be realized and fairly distributed through national policies or market forces'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper1.pdf', 'page': 4}, page_content='alone. International cooperation will be required to enable widespread access to safe AI, harness AI \\nto achieve global public goods and ensure an equitable distribution of the income generated by AI. \\nSome global-scale risks from AI can only be managed effectively through international \\ncooperation.  As AI systems become more powerful, they could pose severe safety and security risks \\nworldwide. Such risks may include potential catastrophes such as the intentional misuse of powerful \\nAI systems to cause widespread harm and the loss of human control over autonomous AI systems. \\nSince such risks can cross borders, governments may not be able to ensure the safety of their own \\ncitizens unless they cooperate with others. \\nInternational cooperation is also required to enable legitimate and effective decision making \\non AI developments affecting the future of all humanity.  Currently, a small number of people in'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper1.pdf', 'page': 4}, page_content='on AI developments affecting the future of all humanity.  Currently, a small number of people in \\na handful of AI companies are making choices that have the potential to affect the lives of people \\naround the world. These choices relate not only to the benefits and risks of AI, but to fundamental \\nquestions about whether, and under what conditions, to develop AI systems that vastly surpass \\nhuman capabilities. \\nThe international community is not prepared for global AI challenges of this scale. Important \\nefforts are under way to strengthen international understanding and cooperation on AI, such as \\nthrough the United Nations and AI Safety Summits. However, these efforts do not yet appear on \\ntrack to handle some of the most challenging potential scenarios facing the global community, such \\nas the need to detect or prevent the development of unacceptably dangerous AI systems. \\nThis discussion paper proposes a robust and agile approach to addressing the issues posed by'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper1.pdf', 'page': 4}, page_content='This discussion paper proposes a robust and agile approach to addressing the issues posed by \\nthe accelerating development of AI.  This approach consists of swiftly developing and adopting an \\ninternational Framework Convention on Global AI Challenges, accompanied by specific protocols \\nto facilitate collaborative action on the most urgent issues. \\nAn international Framework Convention on Global AI Challenges should codify the most \\nimportant shared objectives and principles  for international AI cooperation, namely, the \\ndistribution of global benefits from AI, the mitigation of global risks and the process for legitimate \\ndecision making on key choices affecting the future of humanity. The Framework Convention would \\nalso set out processes to prioritize and facilitate further international collaboration on the most \\nurgent and important issues of AI governance facing the global community, through the development \\nof timely, specific and effective protocols for joint action.'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper1.pdf', 'page': 4}, page_content='of timely, specific and effective protocols for joint action.\\nA Protocol on Global Public Safety and Security Risks from AI should set out the necessary \\nactions by signatories to successfully mitigate the most urgent and severe global-scale AI risks. \\nThis could include a tiered approach: low-risk AI requires no internationally coordinated regulation; \\nhigher-risk AI is subject to coordinated regulation and licensing based on common safety standards; \\nvery high-risk AI is only permitted to be developed and run within an international joint AI lab; and \\nAI that poses an extreme risk to humanity is prohibited from being developed until sufficient safety \\nmeasures can be implemented.'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper1.pdf', 'page': 5}, page_content='2This Protocol should also establish the necessary instruments for international cooperation \\n(building on existing bodies where possible) to implement this system effectively. This could \\ninclude a council to make key political decisions, a commission to provide necessary scientific \\nadvice, an agency to set standards and monitor implementation, a lab to conduct joint AI \\nresearch and an adjudication mechanism to settle disputes. The Protocol could be adopted \\ninitially by a core group of parties but should eventually apply universally to ensure that no \\ncountry develops AI systems that impose unacceptable risks on the rest of humanity.\\nThe proposed Framework Convention and initial Protocol(s) should be adopted as soon \\nas possible  and improved incrementally over time, given the rapid pace of AI development \\nand the (albeit small) possibility that AI systems posing global-scale risks could be developed \\nwithin the next few years.'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper1.pdf', 'page': 5}, page_content='within the next few years.\\nNext steps in advancing this work include  engaging with diverse global stakeholders, \\nincluding states, to develop and refine a model Framework Convention and Protocol(s), stress-\\ntesting proposed measures under different scenarios, integrating recommendations into \\nofficial international negotiation processes and expanding research to fill critical knowledge \\ngaps.\\nFramework Convention on Global AI Challenges\\nSUB-OBJECTIVESPRINCIPLES OBJECTIVE\\n1.\\nA.\\nB.\\nC.\\nH.\\nI.\\nD.\\nE.\\nF.\\n2.\\n3.\\nRealize and share \\nglobal benefits of AI.Mitigate global AI risks. Ensure inclusive \\ndecision making on \\nglobal AI issues.\\nAccess\\nGlobal public goods \\nBenefit sharing Global dialogue and \\nreflection on future AILegitimate and \\neffective decisionsPublic safety\\nConcentration\\nManipulation\\nG.\\nMilitary e.g., preparedness, proportionality, etc. Beneficial, safe and inclusive AI on \\nbehalf of all humanity\\nPOTENTIAL PROTOCOLS'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper1.pdf', 'page': 6}, page_content='3Introduction\\nHumanity may still be vastly underestimating AI. Recent advances in AI are garnering widespread \\nattention, with an accelerating pace of breakthroughs and releases matched by a flourish of media \\ncommentary, public debate and national and international policy initiatives. However, most people \\nare still largely focused on the types of AI systems that exist today, while significantly underestimating \\nand underpreparing for the potential power, pace of development and scale of implications of AI \\nsystems that could exist in the years ahead. \\nAI is currently on track to far surpass humans in terms of the power to interpret and act upon \\nthe world. In recent years, AI systems have reached or surpassed human-level performance across \\nan increasingly wide range of cognitive tasks, such as reading comprehension and language and \\nimage generation (Giattino et al. 2023). These developments have been driven by large increases'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper1.pdf', 'page': 6}, page_content='image generation (Giattino et al. 2023). These developments have been driven by large increases \\nin the amount of computing power (see Figure 1) and in the size of data sets, and improvements \\nin the quality of algorithms used to train AI systems. If these trends continue, the capabilities of \\nAI systems could eventually reach and vastly exceed human performance in most or all cognitive \\ndomains.1 Such cognitive proficiency could then enable interaction with other systems, as well as \\nincreased capabilities for physical action in the world, such as through rapid advances in robotics.\\nFigure 1: Computing Power Used to Train Notable AI Models\\nNote: This graph displays the trend in computing power (compute) used to train large AI models. FLOP = floating-point operations.  \\n \\nSource:  Sevilla and Roldán (2024).\\nAlthough the pace of AI development is highly uncertain, there are reasons to believe that these'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper1.pdf', 'page': 6}, page_content='Although the pace of AI development is highly uncertain, there are reasons to believe that these \\nadvances could occur rapidly (Bengio et al. 2024). The world’s largest companies are investing billions \\nof dollars in AI development, leveraging top talent and computing resources to overcome technical \\nobstacles and unlock additional jumps in capabilities. Automated AI research assistants may also \\ntangibly assist in AI development, resulting in a feedback loop of AI improvements enabling further \\n1 An AI system capable of human-level performance on most or all cognitive tasks is sometimes referred to as artificial general intelligence  \\n(AGI). A system that would be capable of greatly outperforming humans on most or all cognitive tasks is sometimes called artificial \\nsuperintelligence  (ASI). For a more detailed exploration of definitions, see, for example, Morris et al. (2024) and Maas (2023).'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper1.pdf', 'page': 7}, page_content='4AI improvements. Furthermore, AI models typically require many times more computing \\npower to train than to run. Therefore, after one capable AI assistant has been trained, many \\ninstances of it can be run, working constantly and in concert to accelerate AI development yet \\nfurther. In sum, it is possible that AI progress is nearing the very steep part of an exponential \\ncurve, enabling increasingly powerful AI systems (Everitt, Lea and Hutter 2018; see Figure 2).  \\nFigure 2: A Hypothetical Graph of AI Capabilities over Time\\nTIMESYSTEM CAPABILITY\\nD1D2Greatly exceeding \\nhuman-level \\ncapabilities\\nRoughly \\nhuman-level \\ncapabilities\\nNote: A graph of AI system capabilities over time, depicting a hypothetical scenario in which AI systems assist \\nwith AI research. This initiates a positive feedback loop enabling the rate of capabilities development to \\nbecome exponential. In this case, the length of time (D1) to reach approximately human-level capabilities would'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper1.pdf', 'page': 7}, page_content='be longer than the length of time (D2) to greatly exceed human-level capabilities. \\nSource:  CIGI. Adapted from a similar chart shared by the International Center for Future Generations.\\nAI developments in the next few years could have implications far beyond what nearly \\nanyone is currently anticipating or prepared for. Increasingly powerful AI could enable \\nprosperity great enough to erase economic inequalities, or massively amplify them. It could \\ntransform the power balance within and across societies. It could bring about game-changing \\nsolutions to some of the biggest global challenges, such as climate change, while generating \\nnew dangers on a global scale. It could replace humans in an increasing range of core functions, \\nultimately threatening to supersede humans as the dominant societal actors. Humanity may \\ntherefore face choices of unprecedented magnitude and consequence about what kinds of AI \\nto create, for what purposes and under what conditions.'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper1.pdf', 'page': 7}, page_content='to create, for what purposes and under what conditions. \\nThis discussion paper aims to inform discussion on how the international community can \\nbest prepare for and manage the potential implications of advanced AI. The paper begins \\nby exploring three emerging global-scale challenges posed by advanced AI that could require \\ninternational cooperation. These relate to realizing the global benefits of AI, mitigating'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper1.pdf', 'page': 8}, page_content='5the global risks and making legitimate choices about future implications of AI for humanity. The \\npaper then recommends an instrument to help facilitate international cooperation on these issues: \\na Framework Convention on Global AI Challenges. Such a framework convention would have the \\nbreadth and flexibility needed to respond to the urgent and transformative nature of global AI \\nchallenges. Finally, the paper recommends prioritizing the adoption of a specific Protocol on Global \\nPublic Safety and Security Risks from AI, given the potential severity and uncertain timelines of such \\nrisks.\\nGlobal Challenges from \\nAdvanced AI\\nInternational cooperation will be needed to manage emerging global challenges arising from the \\ndevelopment of advanced AI. While many AI issues can be managed at the local or national levels, \\nsome have substantial cross-border effects and cannot be addressed effectively or legitimately by one'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper1.pdf', 'page': 8}, page_content='government alone. To govern these issues, states will likely need to come together to negotiate and \\nimplement some form of international agreement. \\nThis paper examines three global AI challenges in particular which humanity could face in the \\ncoming years, and which likely require international cooperation to overcome.  These are: \\n •how to realize and share the global benefits of AI; \\n •how to mitigate severe global risks posed by AI; and\\n •how to make legitimate and effective decisions  about the future implications of AI for humanity. \\nChallenge One: Realizing and Sharing Global \\nBenefits of AI\\nAdvanced AI systems could bring about considerable benefits. They are expected to accelerate \\neconomic growth by complementing and substituting for human labour and accelerating scientific \\nadvances. This increased productivity could be harnessed to help solve some of the largest challenges'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper1.pdf', 'page': 8}, page_content='humanity faces today. If applied effectively and equitably, AI systems could help alleviate poverty, \\ncure diseases, invent green technologies and empower people around the world with tailored \\nknowledge and advice. AI-driven productivity growth could also significantly increase the quantity \\nand quality of material goods such as food, transportation, energy and housing, as well as intangible \\ngoods in the form of education, entertainment, support and companionship.\\nHowever, many of these positive outcomes will likely not be achieved by market forces alone. \\nGovernment action, and international cooperation in particular, may be required to address three \\nlikely shortcomings: the underutilization of AI systems due to lack of access; the underprovision of \\nglobal public goods from AI; and unequal distribution of AI benefits.\\nFirst, global cooperation may be necessary to ensure that all people are able to access productivity-'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper1.pdf', 'page': 8}, page_content='enhancing AI technologies. People in lower-income countries are already grappling with digital \\ninfrastructure deficits, prohibitive costs of connectivity and barriers to developing digital skills. \\nAs a result, they are unlikely to access and adopt AI tools and services at the same rate as their \\ncounterparts in advanced economies. For example, according to figures from the International \\nTelecommunication Union (2023), just 37 percent of people in Africa use the internet, compared to'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper1.pdf', 'page': 9}, page_content='6up to 91 percent in Europe. Even within wealthy countries, there is a risk that access to the \\nmost advanced technologies may be concentrated among a small number of leading firms and \\nhighly skilled individuals. The lack of access to AI tools has global-scale costs in terms of both \\ninequality and lost productivity. International cooperation could address this shortcoming by \\nprioritizing wide-scale access to safe, secure and trustworthy AI.\\nSecond, international cooperation may be needed to harness the power of AI to produce \\nglobal public goods. These are products and services that provide significant global benefits, \\nbut which private companies and individual governments lack sufficient incentives to provide. \\nSuch goods could include educational resources, vaccines, green technologies and other \\nuseful technologies. The international community could coordinate to produce these goods by \\nsubsidizing the use of advanced AI systems to provide them.'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper1.pdf', 'page': 9}, page_content='subsidizing the use of advanced AI systems to provide them. \\nThird, international cooperation will be required to make the distribution of AI benefits \\nmore equitable. Some of the benefits of an AI-driven productivity surge may be widely \\ndistributed through lower prices. However, a large share of the surplus generated by AI could \\naccrue to a limited number of individuals or organizations controlling the most productive \\nAI systems and associated value chains. International cooperation could address this issue by \\ndesigning tools to fairly tax and redistribute benefits. Designing, implementing and enforcing \\nmechanisms to do so is a considerable challenge, but could be accomplished through, for \\nexample, various types of income transfers or subsidized production of key goods and services. \\nThe productivity gains enabled by advanced AI are potentially large enough to support \\nfar more global income redistribution than has been politically feasible in the past.'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper1.pdf', 'page': 9}, page_content='far more global income redistribution than has been politically feasible in the past. \\nCommitments to such redistribution are more likely to be accepted and honoured if they are \\nmade in advance, before the gains have been realized. This principle is reflected, for example, \\nin the proposed Windfall Clause, whereby AI companies would commit to donate all profits \\nabove a certain level of income (for example, one percent of global economic output) (O’Keefe \\net al. 2020). Ensuring that all of humanity benefits from AI is likely also a moral and political \\nimperative given that the most severe risks from AI affect all of humanity equally. \\nChallenge Two: Addressing Global AI Risks\\nAs a rapidly developing technology with multiple potential capabilities and uses, advanced AI \\nsystems pose numerous risks. A number of these risks are illustrated in the chart below (see \\nFigure 3)2 and described in more detail in Appendix 1. Some of the risks are familiar, such as'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper1.pdf', 'page': 9}, page_content='Figure 3)2 and described in more detail in Appendix 1. Some of the risks are familiar, such as \\nissues of privacy, bias, misinformation and labour market risks (GOV.UK 2024a). But experts \\nhave also raised concerns that AI could pose catastrophic risks (Anderljung et al. 2023; Bengio \\net al. 2024; Critch and Russell 2023). Although such extreme outcomes may seem unlikely, they \\ncannot currently be ruled out.\\n2 The positioning of risks on the chart is intended to be illustrative and does not claim to be comprehensive or authoritative. The \\nauthors welcome feedback, including rationales for alternative positioning as well as suggestions of additional risks.'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper1.pdf', 'page': 10}, page_content='7Figure 3: Scope and Severity of AI Risks\\n \\nSCOPE\\nSEVERITYChallenging Adaptable Catastrophic FatalGlobal\\nNational\\nIndividualUncontrolled\\nsuperintelligence\\nWeaponization\\nAutomated\\nwarfareWidening global inequality\\nHyper-surveillance\\nAutonomous \\nvehicle fatalitiesCyberattacks on critical infrastructure\\nAlgorithmic biasHarm to democratic institutionsMass job loss\\nAI spamRobotic \\nmalfunctions\\nMedical diagnostics failuresPrivacy breaches\\nLoss of jobNational inequalityAI-enabled totalitarianism\\nBehavioural\\nmanipulations\\nNote: AI risks are plotted in two dimensions, scope and severity. Scope refers to the range of a risk’s effects and ranges \\nfrom affecting individuals to affecting the whole world. Severity refers to the seriousness of a risk’s effects and ranges from \\nadaptable, which may be imperceptible or easily mitigated, to fatal, causing death or irrecoverable damage. \\nSource:  CIGI.\\nIn the worst case, AI risks could be both global in scope and extreme in severity. This implies they'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper1.pdf', 'page': 10}, page_content='could cause enormous economic damage or loss of life at the global level. How might such devastating \\noutcomes occur? Here the focus will be on two types of risks of this nature: weaponization and loss \\nof control.3 \\n3 These are not the only possible global catastrophic risks from AI. For example, mass adoption of AI systems and widespread automation of \\ndecision making creates new systemic vulnerabilities that could result in sudden collapse. Loss of control could also result not from sudden \\nAI takeover, but rather from humans being gradually and systematically outcompeted by AIs that can perform their jobs faster, cheaper \\nand more reliably. Another suggested variety of existential threat is one where humanity may not be destroyed or replaced but could suffer \\nvalues lock-in due to the power of human-controlled or autonomous AI to shape human beliefs and prevent further developments in human'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper1.pdf', 'page': 10}, page_content='civilization. This paper focuses on weaponization and loss of control as two particularly clear and important risks.'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper1.pdf', 'page': 11}, page_content='8AI Weaponization\\nAI weaponization concerns the misuse of AI systems to cause harm.  Experts have expressed \\nconcern, for example, that threat actors could use advanced AI technologies and advanced \\nbiotechnologies in tandem to engineer novel pathogens and unleash a deadly pandemic, possibly \\non a global scale (Sandbrink 2023; Urbina et al. 2022). AI may also aid in the development of \\npotent cyberweapons capable of disrupting critical infrastructure globally (Shevlane et al. 2023). \\nGenerative AI systems could allow misinformation to spread at scale to provoke widespread \\nsocietal upheaval, violence and conflict (Matz et al. 2024; Shevlane et al. 2023). And as AI tools \\nbecome even more powerful, they could assist malicious actors in developing new hazards and \\nstrategies for widespread harm that humanity has not yet prepared for. \\nThe challenge is exacerbated by AI broadening the range of actors capable of causing'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper1.pdf', 'page': 11}, page_content='The challenge is exacerbated by AI broadening the range of actors capable of causing \\nsevere harm , potentially empowering terrorist groups, rogue states, organized crime units, \\nand incautious organizations and individuals to develop and deploy such weapons. Although \\nAI will also help defend against such threats, it is not clear that defensive improvements will \\nconsistently keep pace with new offensive capabilities (Garfinkel and Dafoe 2021), or that \\nthese defences (such as mass surveillance and automated cyber defences) will not pose global-\\nscale risks of their own (Peterson and Hoffman 2022).\\nLoss of Control\\nAnother category of AI risks concerns the loss of control of advanced AI systems. As AI \\nsystems become more capable, there are increasing efforts to develop autonomous AI agents \\nthat can make plans and pursue goals with limited oversight (GOV.UK 2024a). AI agents could \\nprove highly useful, but also more difficult to understand and control. Deactivating them'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper1.pdf', 'page': 11}, page_content='prove highly useful, but also more difficult to understand and control. Deactivating them \\ncould also be problematic if, for example, they are integrated into important systems such as \\nfinancial markets or can replicate themselves faster than operators are able to shut them down. \\nScenarios of extreme loss of control could involve the purposeful  elimination or \\ndisempowerment of humanity by a hostile or misaligned AI or group of AIs. Some AI \\nsystems, if their goals are not properly specified or their actions not appropriately limited, may \\nseek to deceive their operators (Hubinger et al. 2024), gather resources and evade shutdown \\nattempts. In the extreme, an AI system exhibiting such misalignment could seek to shut \\nhumanity out of critical global systems such as digital infrastructure or military command \\nstructures. Alternatively, it may seek to eliminate humanity outright. Such outcomes may seem'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper1.pdf', 'page': 11}, page_content='structures. Alternatively, it may seek to eliminate humanity outright. Such outcomes may seem \\nunrealistic, but no techniques currently exist to reliably align an AI’s behaviour with complex \\nor even common-sense human values (Bengio et al. 2024). Autonomous AI systems may pursue \\ngoals that are destructive to humanity if such outcomes are seen as compatible with or desirable \\nfor its learned or programmed objectives. Sufficiently powerful and intelligent systems may \\ncause severe global catastrophes as a result.\\nWhile there remains high uncertainty about the timing and likelihood of such risks, given \\ntheir potential scale and severity, immediate safeguards are warranted. Recent trends \\nsuggest that even the next generation of AI systems could have dangerous capabilities (Fang \\net al. 2024; OpenAI 2023). Especially since capabilities can develop in surprising and hard-to-\\npredict ways (Bowman 2023), this uncertainty calls for a high degree of caution. International'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper1.pdf', 'page': 11}, page_content='predict ways (Bowman 2023), this uncertainty calls for a high degree of caution. International \\ncooperation could prove critical to design and implement mechanisms to monitor the \\ndevelopment of potentially dangerous AI systems globally, identify systems deemed too \\ndangerous to develop and release, prevent the development of such systems if necessary, and \\nensure future AI research and development proceeds safely.'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper1.pdf', 'page': 12}, page_content='9Challenge Three: Making Globally Legitimate \\nand Effective Decisions about How to Govern \\nAdvanced AI\\nThe final global challenge posed by advanced AI is that of making legitimate and effective \\nglobal decisions about how to manage the transformative benefits, catastrophic risks and other \\nfundamental issues AI raises for the future of humanity. Currently, decisions about developing and \\nreleasing new AI systems are being made by a small and unrepresentative group of people in high-\\nincome nations who do not have the legitimacy to make these decisions for the world at large. Such \\ndecisions plausibly impose severe risks on people around the globe and should be made by processes \\nthat appropriately represent the interests of all affected parties.\\nThe prospect of advanced AI poses many fundamental ethical questions for all of humanity. \\nIf large swathes of the economy are automated and economic and scientific progress accelerates,'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper1.pdf', 'page': 12}, page_content='If large swathes of the economy are automated and economic and scientific progress accelerates, \\nhumanity may find itself asking deep questions about how to ensure global prosperity, prioritize \\nproblems to solve, manage major risks and navigate other issues resulting from the societal impacts \\nof advanced AI, such as space exploration and resource exploitation resulting from new technologies. \\nHumanity will also need to decide on such questions as when to delegate oversight of critical systems \\nto AI advisers and agents. What safeguards should be put in place? If different nations make different \\nchoices, how will the potential shifts in global power balances be managed? And if advanced AI \\nsystems gain moral and legal standing themselves, what rights will they have (Sebo and Long 2023)? \\nGiven the complexity of these questions, and the possibility of rapid developments in AI, \\ninclusive processes of reflection and deliberation are needed now.  Such efforts, and the structures'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper1.pdf', 'page': 12}, page_content='and institutions that enable them, could be designed so that whenever humanity faces such questions, \\nits answers are determined by an effective, just, representative and legitimate process.\\nCurrent International Cooperation \\nEfforts Are Insufficient for Global \\nAI Challenges\\nInternational cooperation on AI issues has accelerated with the pace of AI development in recent \\nyears. These efforts demonstrate an encouraging resolve among governments and multilateral \\norganizations to cooperate to address AI challenges. The UN resolution on safe, secure and \\ntrustworthy AI, adopted unanimously by the UN General Assembly in March 2024, covers a broad \\nrange of issues relating to both the benefits and risks of AI (United Nations General Assembly 2024). \\nThe UN Secretary-General has also convened a High-level Advisory Body on Artificial Intelligence \\nto develop recommendations for globally coordinated AI governance, and in September 2024 the'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper1.pdf', 'page': 12}, page_content='to develop recommendations for globally coordinated AI governance, and in September 2024 the \\nUN Summit of the Future will aim to finalize a Global Digital Compact that outlines shared global \\nvalues and principles for AI (Advisory Body on Artificial Intelligence 2023; United Nations 2021). \\nSignificant international cooperation efforts on AI are also being pursued by the G7, the Organisation \\nfor Economic Co-operation and Development (OECD), the African Union, the Council of Europe, \\nthe European Union, the UK AI Safety Summit follow-up process, as well as through various formal \\nand informal bi- and “mini-lateral” discussions (see Box 1 for details).'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper1.pdf', 'page': 13}, page_content='10 \\nBox 1: International Coordination Efforts on AI Issues\\nIn addition to work being conducted under the aegis of the United Nations, a \\nnumber of other international coordination efforts on AI issues are under way. For \\nexample: \\n •The G7 plans to advance the Hiroshima AI Process by building out the \\nmechanisms to monitor voluntary compliance with its Code of Conduct for \\nOrganizations Developing Advanced AI Systems in collaboration with the \\nOECD and other partners. The code calls on organizations developing AI to \\ntake appropriate and commensurate measures to identify, evaluate and mitigate \\npotential safety, security and societal risks (G7 2023). \\n •The African Union  is finalizing a Continental Strategy on AI, which has the \\ndual objectives of promoting AI adoption and addressing its associated risks \\n(African Union 2024). \\n •China  is championing an inclusive approach, announcing a Global Governance \\nInitiative (Ministry of Foreign Affairs, People’s Republic of China 2023) and'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper1.pdf', 'page': 13}, page_content='Initiative (Ministry of Foreign Affairs, People’s Republic of China 2023) and \\nexpressing support for a UN-led process to establish an international AI \\ngovernance institution. \\n •The Council of Europe’s  Framework Convention on AI and Human Rights \\nwill be open to all countries to join and potentially applies to the development \\nof frontier AI models, though each country can decide on its application to the \\nprivate sector (Council of Europe 2024). \\n •The United Kingdom convened an international AI Safety Summit , which \\nculminated in the Bletchley Declaration by the European Union and 28 countries \\naffirming the need for the safe development of AI, including the urgent need to \\nbetter understand risks from frontier models and how to address them (GOV.UK \\n2023). The attendees of the UK AI Safety Summit also agreed to support a scientific \\nconsensus-building report on the “safety of advanced AI,” and the interim report \\nwas published in May 2024 (GOV.UK 2024a).'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper1.pdf', 'page': 13}, page_content='was published in May 2024 (GOV.UK 2024a). \\n •The subsequent Seoul AI Summit  saw countries commit to collaborate on \\ndeveloping common thresholds for severe AI risks and to launch a network of \\nnational AI safety institutes, which could help build consensus around policies \\nand norms (GOV.UK 2024b; 2024c).\\nHowever, these efforts are currently insufficient for managing possible scenarios in which \\nAI systems have rapid, transformative effects around the world . There are no adequate \\nmeasures in place to realize and distribute the scale of potential benefits that advanced AI could \\nmake possible. There is also a lack of measures to prevent or mitigate newly emerging global-\\nscale risks from AI, such as consistent standards and mechanisms to ensure AI development \\nproceeds safely everywhere (Cihon 2019; Trager et al. 2023), and monitoring and enforcement \\ncapacity to ensure universal compliance with them (Heim et al. 2024). Finally, there is a lack'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper1.pdf', 'page': 13}, page_content='capacity to ensure universal compliance with them (Heim et al. 2024). Finally, there is a lack \\nof effective and legitimate processes to make decisions regarding AI that could have lasting \\nimplications for humanity, such as decisions about when and under what conditions to develop \\nAI systems vastly more capable than humans.'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper1.pdf', 'page': 14}, page_content='11In summary, given the potential power and pace of development of advanced AI systems, the \\nsignificant global challenges they may pose, uncertainty about when such challenges may arise, \\nand the apparent inadequacy of current systems to handle these challenges, an effective, future-\\nready approach to international cooperation on AI governance is urgently required. \\nA Framework Convention on \\nGlobal AI Challenges\\nSuccessfully navigating emerging global AI challenges is likely to require unprecedented \\ninternational agreement and cooperation.4 Since advanced AI systems, regardless of where they are \\ndeveloped, can have significant implications for other parties, states will likely only be able to secure \\ntheir interests by cooperating with others. Such cooperation will likely require various verifiable \\nand enforceable international agreements to ensure that all parties meet their commitments. This is'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper1.pdf', 'page': 14}, page_content='likely to be particularly important given the strong incentives for states to, otherwise, seek advantage \\nby breaking or ignoring joint commitments (Horowitz 2018). \\nA Framework Convention on Global AI Challenges could provide a practical and flexible \\ninstrument to help accelerate international cooperation on the effective governance of advanced \\nAI. A framework convention5 can be broad and flexible, allowing the international community to \\nact first on pressing AI challenges while recognizing the full range of issues that must be addressed. \\nWhen signing a framework convention, parties agree on shared objectives and principles, as well as \\non processes for addressing contentious issues in accompanying protocols that tackle specific issues \\nand commitments. Those protocols can then be negotiated and signed individually. Early protocols \\non urgent issues can thus be prioritized while allowing additional time for other protocols that may \\nbe less urgent or more contentious.'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper1.pdf', 'page': 14}, page_content='be less urgent or more contentious. \\nThe following sections outline preliminary suggestions regarding possible key components of a \\nFramework Convention on Global AI Challenges, and a supporting Protocol on AI Safety. Given \\nthe scope and complexity of these issues, many questions remain to be answered through further \\nresearch and negotiation. \\nContents of the Framework Convention\\nObjective\\nThe framework convention should establish a clear, high-level objective, such as “ensuring the \\ndevelopment of beneficial, safe and inclusive artificial intelligence on behalf of all humanity.” \\nSuch a goal is broad enough to encompass a range of sub-objectives aimed at tackling each of the \\nthree global challenges of advanced AI, namely: promoting and distributing the global benefits \\nfrom AI; preventing and mitigating global AI risks; and strengthening global cooperation to ensure \\nlegitimate and effective decision making on current and future AI issues.'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper1.pdf', 'page': 14}, page_content='legitimate and effective decision making on current and future AI issues.\\n4 Global AI challenges are arguably unprecedented in terms of the possible scale and significance of their implications, the limited margin for \\nerror, the strong private and national incentives to default on joint commitments, and various practical obstacles to verifying and enforcing \\ncompliance. Nevertheless, many other areas of international cooperation can serve as partial models and inspiration, such as nuclear energy \\nand nuclear non-proliferation, climate change, aviation, financial institutions and others.\\n5 A framework convention is a kind of international treaty. Examples include the UN Convention on Climate Change (https://unfccc.int/process-\\nand-meetings/what-is-the-united-nations-framework-convention-on-climate-change) and the UN Convention against Transnational Organized \\nCrime (www.unodc.org/unodc/en/organized-crime/intro/UNTOC.html).'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper1.pdf', 'page': 15}, page_content='12Principles\\nThe principles of the framework convention should establish a shared foundation of \\nvalues, priorities and commitments to guide participating states in their negotiations and \\ndecision-making processes. Principles should reflect key shared values such as cooperation, \\ninclusivity, equity, proportionality, effectiveness, preparedness and adaptability.\\nMore specifically, and building on recent work, the principles could:\\n •recognize the necessity of international coordination and cooperation  in addressing the \\nglobal opportunities and challenges presented by advanced AI;\\n •affirm the need for inclusive  decision making to ensure that global benefits and global \\nrisks accrue and are borne equitably  across humanity;\\n •assert that the extent of international cooperation should be proportionate  to the scale of \\nthe global challenges involved; \\n •assert that joint action must be sufficient to be fully effective  in achieving the shared'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper1.pdf', 'page': 15}, page_content='•assert that joint action must be sufficient to be fully effective  in achieving the shared \\nobjectives set out in the framework convention, while at the same time limited  to infringe \\nas little as possible on state sovereignty and other goals; \\n •commit to addressing the wide range of global challenges that AI presents, while \\nprioritizing  work on the most urgent ones, such as critical global risks to public safety; and\\n •recognize that, given the fast-changing nature of AI and uncertainty about future \\nopportunities and risks, joint action should be prepared  to handle the worst-case scenarios, \\nwhile remaining readily adaptable  to a wide range of possible future conditions. \\nOrganizing Bodies\\nThe framework convention should establish any institutional bodies necessary to convene \\nand guide future discussion on specific protocols and commitments, beginning with \\na “Conference of the Parties” of signatory states. Additional institutional bodies may be'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper1.pdf', 'page': 15}, page_content='a “Conference of the Parties” of signatory states. Additional institutional bodies may be \\ndeveloped as required to implement, monitor and enforce specific governance measures. In the \\ninterest of reaching swift agreement, however, it may be advisable to reserve the establishment \\nof such additional institutions for subsequent protocols.\\nOther Components\\nFramework conventions typically include several additional components to aid future \\ndialogue among participatory states. These include mechanisms to review implementation, \\npromote compliance and resolve disputes, along with other implementing clauses.\\nAfter these structural components are established, the framework convention could be signed, \\nallowing parties to develop supporting individual protocols with more specific commitments.'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper1.pdf', 'page': 16}, page_content='13Illustration of Framework Convention and Protocols\\nFigure 4 provides an overview of the proposed framework convention structure and its  \\nrelationship to the accompanying protocols. The examples of potential protocol topics are \\nillustrative only. Some may already be partially covered by existing international agreements or be \\nbetter suited to separate legal instruments. They have been roughly grouped according to which of \\nthe three global AI challenges they help address. \\nFigure 4: International Framework Convention on Global AI Challenges\\nFramework Convention on Global AI Challenges\\nSUB-OBJECTIVESPRINCIPLES OBJECTIVE\\n1.\\nA.\\nB.\\nC.\\nH.\\nI.\\nD.\\nE.\\nF.\\n2.\\n3.\\nRealize and share \\nglobal benefits of AI.Mitigate global AI risks. Ensure inclusive \\nglobal coordination \\nand decision making \\non global AI issues.\\nEnsure widespread and \\nequitable access to \\nsafe AI tools, capacity, \\nskills, etc.\\nHarness AI to achieve \\nglobal public goods on \\nbehalf of all humanity.\\nEnsure equitable'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper1.pdf', 'page': 16}, page_content='Harness AI to achieve \\nglobal public goods on \\nbehalf of all humanity.\\nEnsure equitable \\nbenefit sharing (e.g., \\nglobal distribution of \\nAI productivity gains).Enable legitimate and \\neffective decision \\nmaking on future AI \\ndevelopments affecting \\nall humanity.\\nFoster inclusive global \\nreflection on key \\nquestions related to \\npossible future \\nemergence of AGI \\nand sentient AI.Mitigate AI risks to global \\npublic safety (e.g., \\nweaponization, loss of \\ncontrol).\\nPrevent concentrations \\nof power in the \\ncontrol of AI.\\nMitigate risks of AI \\nsuper-persuasion \\nand protect freedom \\nof thought.\\nG.\\nMitigate global risks \\nfrom military use of \\nAI.e.g., cooperation, inclusivity, equity, \\nproportionality, effectiveness, \\npreparedness and adaptabilityBeneficial, safe and inclusive AI on \\nbehalf of all humanity \\nPOTENTIAL PROTOCOLS'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper1.pdf', 'page': 17}, page_content='14A Protocol on Global Public \\nSafety and Security Risks from \\nAI (“Protocol on AI Safety”)\\nAn early priority under the Framework Convention on Global AI Challenges should be to \\nnegotiate a protocol focused on reducing risks of catastrophic harm from advanced AI. \\nThis suggested prioritization is based on the following considerations: \\n •The potential severity of the harms. Weaponization or loss of control of AI could \\npotentially cause a catastrophic scale of harm, possibly including trillions of dollars in \\neconomic damage and millions or even billions of human deaths. \\n •The possibility of short timelines.  While there remains high uncertainty about the \\npotential timing and likelihood of global-scale AI risks to public safety, there is reason to \\nbelieve that such harms could be possible within even just a few years, or less. This makes \\nacting swiftly to begin reducing these risks a priority.'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper1.pdf', 'page': 17}, page_content='acting swiftly to begin reducing these risks a priority. \\n •A shared interest in success.  Societies share a common interest in avoiding catastrophic \\nsuffering and loss of life. Despite the significant challenges of achieving meaningful \\ninternational cooperation on AI, agreement on focused, shared areas of interest such as \\nsafety and security may be somewhat easier to achieve, whereas agreement on other global \\nAI challenges may take more time. \\nPrioritizing swift progress on a Protocol on AI Safety does not imply that this protocol \\nshould take precedence over other areas. Governments have the capacity to pursue multiple \\ninternational cooperation goals in parallel, and it is possible that other global challenges \\nrelating to AI merit similarly rapid attention and progress. However, global AI catastrophes \\nmust be avoided if humanity is to realize the benefits of AI and have the opportunity to make \\nlong-lasting decisions about its future trajectory.'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper1.pdf', 'page': 17}, page_content='long-lasting decisions about its future trajectory.\\nContents of the Protocol on AI Safety\\nObjective and Principles\\nThe overarching objective of this Protocol is to enable governments and other relevant \\nparties to collaborate effectively to prevent and mitigate severe AI risks to global public \\nsafety. Such risks include the possible misuse or weaponization of powerful AI systems, or \\nthe potential loss of human control over AI, such as through the accidental or intentional \\ndevelopment of an uncontrolled artificial superintelligence.\\nThe principles of this Protocol could include:\\n •Any global or globally coordinated restrictions on AI shall be proportionate to the level of \\nrisk (that is, likelihood times severity of impact) of the AI system in question. \\n •Any global or globally coordinated restrictions on the development or use of AI shall be \\ndesigned to ensure reliable safety from global catastrophic risk (with an adequate margin'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper1.pdf', 'page': 17}, page_content='designed to ensure reliable safety from global catastrophic risk (with an adequate margin \\nof error) while otherwise minimizing negative impacts of such restrictions for other global \\npriorities such as innovation, prosperity, privacy, liberty and so on.\\n •Global risks from AI should only be accepted where they are sufficiently justified by global \\nbenefits from AI.'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper1.pdf', 'page': 18}, page_content='15 •All decisions relating to global-scale risks (that is, risks borne by all of humanity) should be made \\nby a legitimate and globally representative process.\\n •Consideration for the interests and rights of future generations.\\nObligations\\nSignatories to this protocol, recognizing the importance of reducing global risks to public \\nsafety from AI systems to acceptable levels, would mutually commit to several obligations. More \\nresearch, as well as dialogue among global stakeholders, is necessary to determine which specific \\nobligations should be adopted. Monitoring and enforcement procedures necessary to enforce those \\nobligations also require additional development. However, some possible obligations that could be \\nconsidered for the protocol include:\\n •No state shall allow in its sphere of effective control the development or use of an AI system that \\nposes an unacceptable risk to global public safety (unless authorized to do so by the international \\ncommunity).'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper1.pdf', 'page': 18}, page_content='community).\\n •States shall abide by and enforce within their sphere of effective control those standards and \\npolicies established by the international community to manage global risks to public safety, such \\nas risk tolerance thresholds, risk management frameworks, regulations applying to compute \\nproviders and AI model developers, liability regimes, the accreditation of third-party safety \\nevaluators, and so forth.\\n •States shall fully cooperate with verification efforts required by the international community \\nto ensure full compliance with the provisions of the Protocol, such as through appropriate \\nmonitoring of relevant AI facilities within each state’s sphere of effective control.\\nRisk Tolerance Thresholds\\nA central principle of this Protocol is that governance and regulation of AI systems should be \\nproportionate6 to the level of global benefits and global risks associated with such systems.  The'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper1.pdf', 'page': 18}, page_content='proportionate6 to the level of global benefits and global risks associated with such systems.  The \\naim is to ensure an adequate level of safety (for example, a risk of global catastrophic harm that is \\nas low as reasonably practicable) without sacrificing humanity’s ability to reap the many benefits of \\nAI or pursue other global priorities such as human rights and UN Sustainable Development Goals. \\nA tiered, risk-based approach to the regulation of AI would apply a different level of global \\nrestriction based on the assessed risk level of the AI model or system in question (Koessler, \\nSchuett and Anderljung 2024).  An illustrative four-tier system of potential risk tolerance thresholds \\nfor existing or proposed AI models and systems, and their corresponding implications in terms of \\nglobally coordinated governance restrictions, would comprise: \\n →Tier one: Negligible risk  to global public safety. No common or coordinated global restrictions'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper1.pdf', 'page': 18}, page_content='→Tier one: Negligible risk  to global public safety. No common or coordinated global restrictions \\nrequired. Individual governments or multilateral coalitions may regulate such systems or not as \\nthey desire. Globally harmonized liability frameworks may still apply. \\n →Tier two: Manageable risk.  All entities involved in the development or use of such AI systems \\nare required to have a licence. The licensing regime could be nationally administered but must \\nadhere to global common standards. Licensing requirements could include such elements as \\nthird-party safety evaluations and demonstrating sufficient standards of cybersecurity to secure \\nmodel weights from potential leaking or hacking by determined adversaries. \\n →Tier three: Tolerable risk.  AI systems assessed at this level of risk would be permitted to be \\ndeveloped and run exclusively in an international joint AI lab. The purpose of this restriction is to'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper1.pdf', 'page': 18}, page_content='6 Note that versions of this principle are reflected in numerous national and international texts on AI governance, including the Canadian draft \\nlegislation Bill C-27 and Voluntary Code of Conduct, and in the 2024 EU AI Act.'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper1.pdf', 'page': 19}, page_content='16avoid the race dynamics involved in competition between companies or countries that can \\nresult in cutting corners on safety.\\n →Tier four: Unacceptable risk.  AI systems assessed at this level of risk would not be \\npermitted to be developed anywhere until adequate safety and control mechanisms become \\navailable to lower the risks to tolerable levels. \\nThis tiered approach encourages political debate to focus on the level of risk that society \\nis prepared to tolerate. Such decisions could be made with reference to examples from other \\nsafety-critical industries, such as aviation, nuclear energy, transportation infrastructure, \\npharmaceuticals or other analogous sectors. For example, the chance of severe core damage in \\nnuclear plants is typically required to be less than one in 10,000 per year (International Nuclear \\nSafety Advisory Group 1999). Such discussions could also consider the likelihood and value of'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper1.pdf', 'page': 19}, page_content='Safety Advisory Group 1999). Such discussions could also consider the likelihood and value of \\npotential global benefits from the same AI systems, such as in saving lives through accelerated \\nmedical advances, improved prosperity or helping society to address other catastrophic risks \\nsuch as biological risks or climate change.\\nThis approach leaves the technical question of the assessed risk of a given system (that \\nis, the correspondence between the system’s capabilities and the risk it generates) to be \\nanswered by the best available science. These methods are still very much in their infancy \\nand include evaluations of dangerous capabilities, and the association of potential capabilities \\nwith various parameters and features of the AI systems in question, such as the amount of \\ncomputing power used in training (for example, in floating point operations), model size and \\nso on. \\nIn the absence of scientific consensus or certainty regarding the actual level of global'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper1.pdf', 'page': 19}, page_content='so on. \\nIn the absence of scientific consensus or certainty regarding the actual level of global \\nrisk posed by a certain type of AI system, a precautionary approach is likely advisable. \\nA reasonable range of risk estimates should be generated and regulatory decisions should \\nbe informed by the most conservative ones. This would motivate developers to improve the \\nscience of risk evaluation. Although assessing such risks seems difficult now, the science of \\ninterpretability and evaluation is advancing rapidly. It is possible that reliable, transparent and \\nreproducible methods of evaluating model risk will be developed in the coming years.\\nProposed Governance Institutions and Roles\\nThe following are possible institutions and roles that may be required to achieve the \\nobjectives of the Protocol on AI Safety.  Implementing the global risk threshold system \\ndescribed above will require several significant supporting functions, including bodies to'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper1.pdf', 'page': 19}, page_content='described above will require several significant supporting functions, including bodies to \\nprovide scientific advice, decision-making support, technical monitoring and evaluation, and \\ndispute and infringement adjudication. The proposed institutions could be based in or adapted \\nfrom existing entities or developed new if required. The institutions that may be needed are \\nlisted below, with a more detailed description of the key functions of each body included in \\nAppendix 2.\\n •Council:  Political decision making on key issues relating to global AI risk and safety.\\n •Commission:  Scientific research and analysis of state of global AI risk and safety.\\n •Agency: Design, implementation, monitoring and enforcement of shared standards and \\nregulatory system on global AI risk and safety.\\n •Laboratory:  Development and provision of AI systems for AI safety research and other \\nglobal benefits. Only computing facility authorized to train and run AI systems above the'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper1.pdf', 'page': 19}, page_content='global benefits. Only computing facility authorized to train and run AI systems above the \\nmaximum threshold permitted for licensed development.\\n •Adjudicator:  Adjudication of international law and of disputes relating to global AI risk \\nand safety.'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper1.pdf', 'page': 20}, page_content='17Figure 5 summarizes the key components of the Protocol, including its objective and principles, four \\nproposed tiers of action based on global risk tolerance thresholds, and the five proposed supporting \\ninstitutions and their roles.\\nFigure 5: Protocol on Global Public Safety and Security Risks from AI\\nProtocol on AI Safety\\nGLOBAL RISK TOLERANCE THRESHOLDS\\nPROPOSED INSTITUTIONS (ADAPTED OR NEW) AND KEY ROLESPRINCIPLES (e.g.) OBJECTIVE\\nNegligible \\nglobal-scale risk \\nto public safetyTIER ONE: TIER TWO: TIER THREE: TIER FOUR:\\nPolitical decision making (e.g., set risk thresholds, apply sanctions, etc.).COUNCIL\\nCOMMISSION\\nAGENCYNo common global \\nrestrictions required \\nfor this AI.Global common \\nstandards required for \\nlicensing of compute \\nproviders, developers \\nand users of this AI. \\nScientific research and analysis to assess current and potential global risks and benefits of AI. Development and use \\nof this AI restricted to \\ninternational joint AI \\nlaboratory and for'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper1.pdf', 'page': 20}, page_content='of this AI restricted to \\ninternational joint AI \\nlaboratory and for \\npurposes of advancing \\nshared global priorities.\\nStandard setting for licensing regime of compute providers, AI developers and users, and \\nverification and enforcement.\\nLABORATORY\\nJoint computing resources authorized to develop and use advanced AI, for global benefit.\\nADJUDICATOR\\nAdjudication of international disputes relating to global AI risk and safety.This AI prohibited \\nuntil adequate \\nsafety and control \\nmechanisms \\navailable.Manageable \\nglobal-scale risk \\nto public safetyTolerable \\nglobal-scale risk \\nto public safetyUnacceptable \\nglobal-scale risk \\nto public safety•Regulation proportionate to risk\\n•Weigh global risks against global \\nbenefits\\n•Fair and equitable distribution of \\nbenefits and risks\\n•Legitimate and globally \\nrepresentative processMitigate AI risks to global public safety \\n(e.g., weaponization, loss of control)'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper1.pdf', 'page': 21}, page_content='18Illustration of the Protocol in Action\\nThe Protocol is designed to provide a framework for action that ensures global public \\nsafety and security under a multitude of possible future scenarios.  The following is an \\nillustration of how the framework could function under two simplified and opposite scenarios.\\n •Scenario one: AI capabilities advance more slowly than expected, accompanied by \\nbreakthroughs in successful AI control and safety techniques.  In this scenario, few if \\nany AI systems would be capable of producing global catastrophic harms. Most AI systems \\ncould be governed at the national level, with international coordination necessary only to \\nensure basic common standards, such as adequate cybersecurity to prevent the hacking \\nand dissemination of the most powerful models to malicious actors, and rules against the \\nopen release of models that could be used to cause widespread harm. Few, if any, AI models'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper1.pdf', 'page': 21}, page_content='open release of models that could be used to cause widespread harm. Few, if any, AI models \\nwould need to be restricted to only being developed and run in the joint AI laboratory, and \\nnone would be prohibited from development entirely. \\n •Scenario two: AI capabilities advance rapidly, but no reliable mechanism has yet been \\ndeveloped to reliably control or align AI systems.  This scenario would call for much \\nstronger restrictions. The globally coordinated licensing regime would need to prevent \\nanyone inside the regulated system from producing dangerous AI models and prevent \\nanyone outside the regulated system from having access to the computing power or other \\ninputs needed to produce dangerous AI models. Many of the most advanced AI systems \\nwould be too dangerous to be produced by individual companies or governments and would \\nneed to be restricted to only being developed and run in the joint lab. Finally, even the joint'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper1.pdf', 'page': 21}, page_content='need to be restricted to only being developed and run in the joint lab. Finally, even the joint \\nlab would hold back from training the most powerful models possible, out of concern that \\nbased on existing safeguards, such systems could possibly evade human control. \\nReality could turn out to be close to either of these scenarios, or various points in between. \\nThere could also be shifts in either direction from one scenario to another, such as if sudden \\nbreakthroughs in safety research allow many more forms of AI to be considered safe or, \\nalternatively, if sudden breakthroughs in algorithmic efficiency or falls in the cost of computing \\npower allow many more actors (including irresponsible or malicious ones) to produce AI with \\ndangerous capabilities. The value of the proposed approach is that it puts in place the \\ninfrastructure needed to enable the various types of coordinated action required to address \\ndifferent possible scenarios as they emerge. \\nChallenges, Opportunities and'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper1.pdf', 'page': 21}, page_content='different possible scenarios as they emerge. \\nChallenges, Opportunities and \\nNext Steps\\nThe proposed Framework Convention on Global AI Challenges and accompanying \\nprotocols are highly ambitious, requiring an arguably unprecedented degree of international \\ncooperation to implement. Achieving such cooperation may be especially challenging \\nin the context of political polarization within societies that could undermine support for \\ninternational agreement, and geopolitical tensions that could make AI development more \\ncompetitive, secretive, risk-tolerant and, thus, harder to control (Danzig 2018; Clare and Ruhl'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper1.pdf', 'page': 22}, page_content='192024). Overcoming these obstacles will require a strong shared understanding of the risks and of the \\neffective means of managing them.7\\nSeveral technological hurdles will also have to be overcome to effectively implement the \\nFramework Convention. Enforcing risk assessment requirements for different training run \\nthresholds may require detecting and quantifying how computing power is being used around \\nthe world, and potentially excluding some actors from leveraging it (Sastry et al. 2024). However, \\nsignificant research is still required before many of the technologies such a system would require \\nare implementation ready. More research is similarly needed to develop evaluation tools to reliably \\ndetect dangerous capabilities in new AI models, information security practices to protect critical \\ninformation about advanced AI models and other technical aspects of the risk management proposals \\nassociated with the Protocol on AI Safety.'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper1.pdf', 'page': 22}, page_content='associated with the Protocol on AI Safety.\\nThere are multiple important governance challenges to overcome.  These include, for example, \\ndetermining what degree of safety assurance should be required before the development of potentially \\ncatastrophic technologies can continue. How can such assurance be measured, and by whom? \\nIs it even technically feasible to obtain such assurance for unprecedented technologies (Downer \\n2024)? There are important uncertainties about many of the specific proposals detailed above, too. \\nThis includes developing ways to incentivize states to participate in governance institutions that \\npotentially constrain their ability to invest in and deploy new technologies, and how to verify and \\nenforce compliance with those constraints.\\nEffective international cooperation on AI may be needed very soon, given the rapid pace of \\nadvances in AI capabilities. This creates additional challenges, as it requires a much-accelerated'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper1.pdf', 'page': 22}, page_content='advances in AI capabilities. This creates additional challenges, as it requires a much-accelerated \\nprocess for reaching international agreement on at least the core actions needed to address the \\nmost urgent and severe shared concerns. Such action may be needed before a full understanding \\nof the risks and optimal responses is available. This also highlights the need to swiftly expand and \\naccelerate technical and governance research to inform and improve international cooperation \\nefforts as soon as possible. \\nDespite these daunting challenges, the seriousness of the risks and the size of the potential \\nbenefits also create enormous incentives for states to cooperate to avoid disaster and secure \\nprosperity. Surveys indicate that the public is also wary of advanced AI and supportive of efforts \\nto reduce risks, creating domestic political incentives for international action (Colson, n.d.; 2023).'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper1.pdf', 'page': 22}, page_content='There is also precedent for international cooperation on AI and other technological risks, including \\nevidence of shared interest among the United States and China on issues such as keeping autonomous \\nweapons under human oversight and not integrating them into nuclear systems (Hass and Kahl 2024). \\nBoth the United States and China, as well as 26 other countries and the European Union, also signed \\nthe Bletchley Declaration (2023), which noted AI’s potentially transformative effects and significant \\nrisks and the need for international collaboration to address them.\\nIn this context, immediate next steps to advance international cooperation on emerging global \\nAI challenges could include:\\n •engaging with diverse global stakeholders to develop and refine the proposed Framework \\nConvention and Protocol;\\n •stress testing proposed measures for their likely effectiveness under challenging scenarios;\\n •encouraging ongoing multilateral negotiations, such as the AI Safety Summits and UN'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper1.pdf', 'page': 22}, page_content='•encouraging ongoing multilateral negotiations, such as the AI Safety Summits and UN \\nconsultations, to adopt the proposed measures;\\n7 The interim International Scientific Report on the Safety of Advanced AI (GOV.UK 2024a) provides an important step in building shared \\nunderstanding of the risks. This, combined with additional efforts such as “track two” discussions among scientists and cooperation between \\nnational AI Safety Institutes and other bodies, could lay the foundation for the proposed international commission dedicated to this purpose. \\nSimilar levels of effort are required to build shared understanding on governance mechanisms.'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper1.pdf', 'page': 23}, page_content='20 •funding and expanding research and policy development efforts to fill critical knowledge \\ngaps; and\\n •initiating processes to draft and adopt international agreements with the proposed \\nmeasures and institutions needed to meet emerging global AI challenges.\\nConclusion\\nHumanity is unprepared for the scale of global AI challenges it could soon face and \\nlacks the mechanisms for international cooperation needed to manage such challenges \\neffectively. Given the pace of development in AI capabilities, a business-as-usual approach \\nto international cooperation is unlikely to be sufficient. Existing approaches would likely \\nprove incapable of dealing with some of the most challenging possible scenarios, such as \\nthose arising from the near-term potential to develop AI systems with vastly superhuman \\ncapabilities. That makes it prudent to design, stress test and establish effective measures in \\nadvance. This proactive approach to international cooperation on AI governance also has the'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper1.pdf', 'page': 23}, page_content='advance. This proactive approach to international cooperation on AI governance also has the \\nadvantage of limiting the risk that governments, faced with a sudden AI crisis, implement ill-\\nconsidered or counterproductive responses. \\nThe proposed approach of a Framework Convention on Global AI Challenges,  \\nsupplemented by supporting protocols on urgent and severe global-scale challenges \\nsuch as risks to public safety, provides a flexible and practical way forward. Specifically, \\nit provides a platform for rapid universal agreement on high-level objectives and principles, \\ncombined with equally rapid concrete cooperation among key actors on the most urgent areas \\nof shared concern. Despite this flexible framework, reaching international agreement in time \\nwill be extremely challenging. Success will require a shared focus on the common interest \\nof humanity in safely navigating this critical juncture, combined with an ability to mobilize'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper1.pdf', 'page': 23}, page_content='of humanity in safely navigating this critical juncture, combined with an ability to mobilize \\nmultiple facets of human ingenuity to solve the many technical and policy problems involved.\\nAcknowledgements\\nThe authors would like to thank the many people (from five continents) who contributed \\nideas and feedback to the development of this discussion paper. While their perspectives \\nmay diverge, they share a common commitment to helping humanity successfully navigate \\nthe global challenges raised by advanced AI. The authors also wish to thank the CIGI Public \\nAffairs team for their invaluable collaboration, and the broader CIGI community for their \\nsupport. Finally, the authors wish to acknowledge Paul Samson, president of CIGI, for astute \\nand insightful guidance, as well as substantive contributions to the discussion paper.'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper1.pdf', 'page': 24}, page_content='21Appendix 1: Descriptions of AI Risks in Figure 3  \\nRisk Description \\nLoss of job AI is expected to cause economic dislocation as it transforms the economy \\n(Georgieva 2024). This could significantly disrupt the lives of affected families \\nand individuals.\\nMedical diagnostics failures AI could revolutionize medical diagnostics, but overreliance on AI poses risks \\nof misdiagnosis and harmful treatment choices (Macmillan 2024). \\nAutonomous vehicle fatalities Though AI-enabled services such as self-driving cars may ultimately be safer, \\nthey will likely experience problems as they are deployed in the real world \\n(Muzahid et al. 2023). \\nPrivacy breaches AI’s reliance on vast amounts of data increases the risk of privacy breaches, \\npotentially affecting millions (Passeri 2023). \\nRobotics malfunctions AI and robotics technologies will allow autonomous systems to take on many \\nmore roles in society, such as in logistics and manufacturing. But especially'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper1.pdf', 'page': 24}, page_content='more roles in society, such as in logistics and manufacturing. But especially \\ninitially, these systems could malfunction in various dangerous ways when \\ndeployed in the real world (Schneier and Ottenheimer 2023). \\nBehavioural manipulations AI may be used to generate persuasive, highly tailored propaganda that \\ncould make it easier to manipulate people on a large scale (Burtell and \\nWoodside 2023). \\nAlgorithmic bias As AI systems gain influence over societal decisions, biased decision making \\nthreatens to disadvantage specific groups. AI bias impacts critical areas such \\nas hiring, policing, incarceration, marketing and insurance (Mehrabi et al. \\n2021). \\nMass job loss AI will boost productivity, but also may lead to economic upheaval as \\nprices fall and jobs shift (Bughin et al. 2018). These disruptions will fall \\ndisproportionately on certain groups and sectors. \\nCyberattacks on critical \\ninfrastructure According to the United Kingdom’s National Cyber Security Centre (2024),'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper1.pdf', 'page': 24}, page_content='infrastructure According to the United Kingdom’s National Cyber Security Centre (2024), \\nAI will “almost certainly” increase the volume and severity of cyberattacks in \\ncoming years. These attacks pose a threat to individuals, financial institutions, \\npublic services, corporate information and government infrastructure. \\nHyper-surveillance Cheap and effective AI surveillance could threaten civil liberties. AI \\nsurveillance tools are already in use in at least 75 countries (Feldstein 2019). \\nHarm to democratic institutions AI systems could be used to generate individually tailored, persuasive \\npropaganda, threatening democratic systems by degrading the information \\nenvironment (Matz et al. 2024). \\nAutomated warfare AI is expected to have many military uses, from improved sensors and \\ntargeting to lethal autonomous weapon systems. AI systems could increase \\nthe speed at which war is fought, as they collect and process data much'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper1.pdf', 'page': 24}, page_content='the speed at which war is fought, as they collect and process data much \\nfaster than human operators. Militaries may be incentivized to use AI systems \\nwhenever possible for fear of being outmanoeuvred by their adversaries. This \\nhas led some researchers to raise worries about the possibility of hyperwar, \\na war directed by AI systems that moves faster than any person can \\nunderstand or control (Scharre 2023). Such a war may escalate extremely \\nquickly, becoming a flash war (Johnson 2022).'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper1.pdf', 'page': 25}, page_content='22Risk Description \\nAI-enabled totalitarianism AI systems excel at autonomously collecting and processing enormous \\namounts of data. All governments will have to manage risks from enhanced \\nsurveillance and control, but in autocratic regimes the prospect of an \\n“AI-tocracy” is particularly concerning (Beraja 2023). In the worst case, \\noppressive AI-powered regimes may prove impossible to dislodge (Caplan \\n2008).\\nWidening global inequality As AI systems become more powerful and economically useful, they could \\nallow the companies or individuals who control them to amass power and \\nunduly influence political decision making through regulatory capture and \\nother mechanisms (Nolan 2023). AI may also benefit high-income workers or \\nowners of capital the most, exacerbating global inequality (Georgieva 2024).\\nWeaponization AI tools could make it easier to access information and synthesize dangerous \\npathogens (Batalis 2023). This could increase the threat posed by states,'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper1.pdf', 'page': 25}, page_content='pathogens (Batalis 2023). This could increase the threat posed by states, \\ngroups or individuals in developing and deploying bioweapons. Many AI \\napplications in biotechnology and other areas will be dual use (Urbina et al. \\n2022).\\nUncontrolled superintelligence It may be difficult to train AI systems that do exactly what users intend, \\nespecially when they are performing complicated tasks in the real world. \\nMany researchers are concerned that competitive pressures will lead AI \\ndevelopers to release models that end up taking actions that harm people \\n(Ji 2024).\\nFor example, an AI could be using tricks or shortcuts to solve problems \\nin its training data that have disastrous effects in the real world (OpenAI \\n2023). Or the goals the system learned in training might not work well in the \\nfull range of real-world scenarios (Shah et al. 2022). Or, perhaps worst of \\nall, a superintelligent AI system could “realize” that — whatever its goals —'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper1.pdf', 'page': 25}, page_content='all, a superintelligent AI system could “realize” that — whatever its goals — \\namassing power and disabling opportunities to turn it off would be helpful \\n(Carlsmith 2022). Such a system may appear cooperative at first but take \\nover global systems once it has the chance (Hubinger et al. 2024).\\nSuch a system could be powerful enough to threaten all of humanity (Piper \\n2020).'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper1.pdf', 'page': 26}, page_content='23Appendix 2: Summary of Proposed Institutions, Roles and Functions\\nThis table summarizes the possible institutions, roles and key functions that may be required to \\nachieve the objectives of the Protocol on AI Safety. The proposed institutions could be adapted \\nfrom existing entities or developed new if required. These institutions could also serve functions \\nof other protocols under the proposed Framework Convention on Global AI Challenges.  \\nProposed \\nInstitution Role Possible Key Functions\\nCouncil Political decision making on \\nkey issues relating to global AI \\nrisk and safety.• Facilitate effective and legitimate decision \\nmaking  on key collective decisions to ensure global \\nAI safety, including:\\n –amendments to protocol;\\n –risk threshold tiers;\\n –priorities for joint AI development; and\\n –enforcement actions.\\n• Consider recommendations of commission, agency \\nand laboratory.\\n• Conduct deliberative assemblies.\\nCommission Scientific research and \\nanalysis of state of global AI'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper1.pdf', 'page': 26}, page_content='Commission Scientific research and \\nanalysis of state of global AI \\nrisk and safety.• Assess risk levels of various types of AI models \\nand systems  based on best available empirical \\nevidence (e.g., capabilities evaluations) as well as \\nproxies (e.g., compute usage, model parameters) for \\nmeasuring them. \\n• Update assessed risk levels of various types of AI \\nmodels on an ongoing basis based on technological \\ndevelopments, safety improvements and improved \\navailable data and research.\\n• Provide technical advice and recommendations to the \\ncouncil and the agency.'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper1.pdf', 'page': 27}, page_content='24Proposed \\nInstitution Role Possible Key Functions\\nAgency Design, implementation, \\nmonitoring and enforcement \\nof shared standards and \\nregulatory system on global AI \\nrisk and safety.• Develop common standards for licensing of compute \\nproviders, AI developers and AI users, as required for \\nensuring safety from global AI risk.\\n• Develop international and recommended national \\nlegal framework for liability of compute providers, \\nAI developers and AI users, as required for ensuring \\nsafety from global AI risk.\\n• Accredit  national or other AI safety organizations \\nresponsible for licensing and auditing compute \\nproviders, AI model developers and AI model users \\nrelated to global catastrophic risk from AI.\\n• Provide direct services (e.g., licensing and audit) \\nin countries lacking access to a national or other \\naccredited body.\\n• Conduct monitoring  of state party compliance with \\nthe provisions of the agreement, including through \\njurisdiction-level and firm-level monitoring.'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper1.pdf', 'page': 27}, page_content='the provisions of the agreement, including through \\njurisdiction-level and firm-level monitoring.\\n• Set guidelines on the appropriate and justified \\nenforcement  of the provisions of the agreement. \\n –Recommend to member states the appropriate \\nenforcement mechanisms in response to a given \\ninstance of non-compliance.\\nLaboratory Provision of compute resources \\nand development of AI for \\nAI safety and other global \\nbenefits. • Manage and run the only computing facility  that is \\nauthorized to train AI systems above the maximum \\nthreshold permitted for licensed development.\\n• Develop and run AI systems  above the maximum \\nthreshold permitted for licensed development, where \\nauthorized by the council on recommendation of the \\nagency, and when justified by the potential global \\nbenefits.\\n• Conduct AI safety research  on behalf of the global \\ncommunity.\\nAdjudicator Adjudication of international \\nlaw and of disputes relating to'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper1.pdf', 'page': 27}, page_content='community.\\nAdjudicator Adjudication of international \\nlaw and of disputes relating to \\nglobal AI risk and safety.• Adjudicate international law related to global AI \\nrisk and safety. \\n –Adjudicate based on existing international law and \\non new legal frameworks adopted by the council.\\n –Adjudicate disputes between state parties.\\n –Adjudicate cases in jurisdictions that lack adequate \\nlegal frameworks (e.g., liability regimes).\\n• Provide findings and recommend action (e.g., \\nremedies, penalties) to council.'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper1.pdf', 'page': 28}, page_content='25Works Cited\\nAdvisory Body on Artificial Intelligence. 2023. Interim Report: Governing AI for Humanity.  December. New York, NY: \\nUnited Nations. www.un.org/sites/un2.un.org/files/un_ai_advisory_body_governing_ai_for_humanity_  \\ninterim_report.pdf .\\nAfrican Union. 2024. “African Ministers Adopt Landmark Continental Artificial Intelligence Strategy, African Digital \\nCompact to drive Africa’s Development and Inclusive Growth.” Press release, June 17. https://au.int/en/\\npressreleases/20240617/african-ministers-adopt-landmark-continental-artificial-intelligence-strategy.\\nAnderljung, Markus, Joslyn Barnhart, Anton Korinek, Jade Leung, Cullen O’Keefe, Jess Whittlestone, Shahar Avin et \\nal. 2023. “Frontier AI Regulation: Managing Emerging Risks to Public Safety.” arXiv, November 7.  \\nhttps://doi.org/10.48550/arXiv.2307.03718.\\nBatalis, Steph. 2023. “AI and Biorisk: An Explainer.” Center for Security and Emerging Technology, December.'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper1.pdf', 'page': 28}, page_content='https://cset.georgetown.edu/publication/ai-and-biorisk-an-explainer/\\nBengio, Yoshua, Geoffrey Hinton, Andrew Yao, Dawn Song, Pieter Abbeel, Trevor Darrell, Yuval Noah Harari et al. \\n2024. “Managing extreme AI risks amid rapid progress.” Science  384 (6698): 842–45.  \\nhttps://doi.org/10.1126/science.adn0117.\\nBeraja, Martin, Andrew Kao, David Y. Yang and Noam Yuchtman. 2023. “AI-tocracy.” The Quarterly Journal of \\nEconomics  138 (3): 1349–1402. https://doi.org/10.1093/qje/qjad012.\\nBowman, Samuel R. 2023. “Eight Things to Know about Large Language Models.” arXiv, April 2.  \\nhttp://arxiv.org/abs/2304.00612.\\nBughin, Jacques, Jeongmin Seong, James Manyika, Michael Chui and Raoul Joshi. 2018. “Notes from the AI \\nfrontier: Modeling the impact of AI on the world economy.” McKinsey Global Institute, September 4.  \\nwww.mckinsey.com/featured-insights/artificial-intelligence/notes-from-the-ai-frontier-modeling-the-  \\nimpact-of-ai-on-the-world-economy .'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper1.pdf', 'page': 28}, page_content='impact-of-ai-on-the-world-economy .\\nBurtell, Matthew and Thomas Woodside. 2023. “Artificial Influence: An Analysis Of AI-Driven Persuasion.” arXiv, \\nMarch 15. https://doi.org/10.48550/arXiv.2303.08721\\nCaplan, Bryan. 2008. “The totalitarian threat.” In Global Catastrophic Risks , edited by Nick Bostrom and Milan M. \\nĆirković, 504–30. Oxford, UK: Oxford University Press. https://doi.org/10.1093/oso/9780198570509.003.0029.\\nCarlsmith, Joe. 2022. “Is Power-Seeking AI an Existential Risk?” arXiv, June 16. https://doi.org/10.48550/\\narXiv.2206.13353.\\nCihon, Peter. 2019. Standards for AI Governance: International Standards to Enable Global Coordination in AI \\nResearch & Development . Future of Humanity Institute Technical Report. April. www.fhi.ox.ac.uk/wp-content/\\nuploads/Standards_-FHI-Technical-Report.pdf.\\nClare, Stephen and Christian Ruhl. 2024. Great Power Competition and Transformative Technologies . Founders'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper1.pdf', 'page': 28}, page_content='Pledge. January. www.founderspledge.com/research/great-power-competition-and-transformative-\\ntechnologies-report .\\nColson, Daniel. n.d. “New Poll Finds Preventing Catastrophic Outcomes is the Top AI Policy Objective for \\nAmericans, Majority Support Regulation of Deepfakes, and Ban on AI-Written News Articles.”  \\nArtificial Intelligence Policy Institute. https://theaipi.org/poll-biden-ai-executive-order-10-30-2/.\\n———. 2023. “Overwhelming Majority of Voters Believe Tech Companies Should be Liable for Harm Caused by \\nAI Models, Favor Reducing AI Proliferation and Law Requiring Political Ad Disclose Use of AI.” Artificial \\nIntelligence Policy Institute, September 19. https://theaipi.org/poll-shows-voters-oppose-open-sourcing-ai-\\nmodels-support-regulatory-representation-on-boards-and-say-ai-risks-outweigh-benefits-2/.'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper1.pdf', 'page': 29}, page_content='26Council of Europe. 2024. “Council of Europe Framework Convention on Artificial Intelligence and Human \\nRights, Democracy and the Rule of Law.” Council of Europe Treaty Series, May 10. CETS 225 - Council \\nof Europe Framework Convention on Artificial Intelligence and Human Rights, Democracy and the Rule \\nof Law. www.coe.int/en/web/artificial-intelligence/the-framework-convention-on-artificial-intelligence .\\nCritch, Andrew and Stuart Russell. 2023. “TASRA: A Taxonomy and Analysis of Societal-Scale Risks from AI.” \\narXiv, June 14. http://arxiv.org/abs/2306.06924.\\nDanzig, Richard. 2018. Technology Roulette: Managing Loss of Control as Many Militaries Pursue \\nTechnological Superiority . Washington, DC: Center for a New American Security.\\nDowner, John. 2024. Rational Accidents: Reckoning with Catastrophic Technologies . Cambridge,  \\nMA: MIT Press.\\nEveritt, Tom, Gary Lea and Marcus Hutter. 2018. “AGI safety literature review.” arXiv, May 21.  \\nhttps://doi.org/10.48550/arXiv.1805.01109.'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper1.pdf', 'page': 29}, page_content='https://doi.org/10.48550/arXiv.1805.01109.\\nFang, Richard, Rohan Bindu, Akul Gupta, Qiusi Zhan and Daniel Kang. 2024. “LLM Agents can Autonomously \\nHack Websites.” arXiv, February 16. https://doi.org/10.48550/arXiv.2402.06664.\\nFeldstein, Steven. 2019. “The Global Expansion of AI Surveillance.” Carnegie Endowment for International \\nPeace, September 17. https://carnegieendowment.org/research/2019/09/the-global-expansion-of-ai-\\nsurveillance?lang=en.\\nG7. 2023. “Hiroshima Process International Code of Conduct for Organizations Developing Advanced AI \\nSystems.” G7 2023 Hiroshima Summit, October 30. www.mofa.go.jp/files/100573471.pdf.\\nGarfinkel, Ben and Allan Dafoe. 2021. “How does the offense-defense balance scale?” In Emerging \\nTechnologies and International Stability , 1st ed., edited by Todd S. Sechser, Neil Narang and Caitlin \\nTalmadge, 247–74. Abingdon, UK: Routledge.\\nGeorgieva, Kristalina. 2024. “AI Will Transform the Global Economy. Let’s Make Sure It Benefits Humanity.”'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper1.pdf', 'page': 29}, page_content='IMF Blog , January 14. www.imf.org/en/Blogs/Articles/2024/01/14/ai-will-transform-the-global-economy-\\nlets-make-sure-it-benefits-humanity.\\nGiattino, Charlie, Edouard Mathieu, Veronika Samborska and Max Roser. 2023. “Artificial Intelligence.”  \\nOur World in Data. https://ourworldindata.org/artificial-intelligence.\\nGOV.UK. 2023. “The Bletchley Declaration by Countries Attending the AI Safety Summit, 1-2 November \\n2023.” www.gov.uk/government/publications/ai-safety-summit-2023-the-bletchleydeclaration/  \\nthe-bletchley-declaration-by-countries-attending-the-ai-safety-summit-1-2-november-2023.\\n———. 2024a. International Scientific Report on the Safety of Advanced AI: Interim Report . May 17.  \\nwww.gov.uk/government/publications/international-scientific-report-on-the-safety-of-advanced-ai .\\n———. 2024b. “Seoul Declaration for safe, innovative and inclusive AI by participants attending the Leaders’ \\nSession: AI Seoul Summit, 21 May 2024.” Department for Science, Innovation & Technology Policy'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper1.pdf', 'page': 29}, page_content='Session: AI Seoul Summit, 21 May 2024.” Department for Science, Innovation & Technology Policy \\nPaper, May 21. www.gov.uk/government/publications/seoul-declaration-for-safe-innovative-and-\\ninclusive-ai-ai-seoul-summit-2024/seoul-declaration-for-safe-innovative-and-inclusive-ai-by-participants-\\nattending-the-leaders-session-ai-seoul-summit-21-may-2024.\\n———. 2024c. “Seoul Statement of Intent toward International Cooperation on AI Safety Science, AI Seoul \\nSummit 2024 (Annex).” Department for Science, Innovation & Technology Policy Paper, May 21. \\nwww.gov.uk/government/publications/seoul-declaration-for-safe-innovative-and-inclusive-ai-ai-seoul-\\nsummit-2024/seoul-statement-of-intent-toward-international-cooperation-on-ai-safety-science-ai-seoul-\\nsummit-2024-annex.\\nHass, Ryan and Colin Kahl. 2024. “Laying the groundwork for US-China AI dialogue.” Brookings Institution, \\nApril 5. www.brookings.edu/articles/laying-the-groundwork-for-us-china-ai-dialogue/.'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper1.pdf', 'page': 30}, page_content='27Heim, Lennart, Tim Fist, Janet Egan, Sihao Huang, Stephen Zekany, Robert Trager, Michael A. Osborne and \\nNoa Zilberman. 2024. “Governing Through the Cloud: The Intermediary Role of Compute Providers in AI \\nRegulation.” arXiv, March 26. https://doi.org/10.48550/arXiv.2403.08501.\\nHill, Michael. 2023. “Generative AI phishing fears realized as model develops ‘highly convincing’ emails in \\n5\\xa0minutes.” CSO, October 24. www.csoonline.com/article/656698/generative-ai-phishing-fears-realized-as-\\nmodel-develops-highly-convincing-emails-in-5-minutes.html.\\nHorowitz, Michael C. 2018. “Artificial Intelligence, International Competition, and the Balance of Power.”  \\nTexas National Security Review  1 (3): 36–57. https://doi.org/10.15781/T2639KP49.\\nHubinger, Evan, Carson Denison, Jesse Mu, Mike Lambert, Meg Tong, Monte MacDiarmid, Tamera Lanham et \\nal. 2024. “Sleeper Agents: Training Deceptive LLMs that Persist Through Safety Training.” arXiv, January 17. \\nhttps://doi.org/10.48550/arXiv.2401.05566.'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper1.pdf', 'page': 30}, page_content='https://doi.org/10.48550/arXiv.2401.05566.\\nInternational Nuclear Safety Advisory Group. 1999. Basic Safety Principles for Nuclear Power Plants — 75-INSAG-3 \\nRev. 1 . Vienna, Austria: International Atomic Energy Agency.\\nInternational Telecommunication Union. 2023. Measuring digital development: Facts and Figures 2023 . \\nwww.itu.int/itu-d/reports/statistics/facts-figures-2023/ .\\nJi, Jiaming, Tianyi Qiu, Boyuan Chen, Borong Zhang, Hantao Lou, Kaile Wang, Yawen Duan et al. 2024.  \\n“AI Alignment; A Comprehensive Survey.” arXiv, May 1. https://doi.org/10.48550/arXiv.2310.19852.\\nJohnson, James. 2022. “AI, Autonomy, and the Risk of Nuclear War.” War on the Rocks, July 29.  \\nhttps://warontherocks.com/2022/07/ai-autonomy-and-the-risk-of-nuclear-war/.\\nKinniment, Megan, Lucas Jun Koba Sato, Haoxing Du, Brian Goodrich, Max Hasin, Lawrence Chan, Luke Harold \\nMiles et al. 2024. “Evaluating Language-Model Agents on Realistic Autonomous Tasks.” arXiv, January 4.'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper1.pdf', 'page': 30}, page_content='https://doi.org/10.48550/arXiv.2312.11671. \\nKoessler, Leonie, Jonas Schuett and Markus Anderljung. 2024. “Risk thresholds for frontier AI.” arXiv, June 20. \\nhttps://arxiv.org/abs/2406.14713 .\\nMaas, Matthijs M. 2023. “Concepts in Advanced AI Governance: A Literature Review of Key Terms and Definitions.” \\nAI Foundations Report 3 . https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4612473.\\nMacmillan, Carrie. 2024. “Generative AI for Health Information: A Guide to Safe Use.” Yale Medicine, January 8. \\nwww.yalemedicine.org/news/generative-ai-artificial-intelligence-for-health-info.\\nMatz, Sandra, Jake Teeny, Sumer S. Vaid, Gabriella M. Harari and Moran Cerf. 2024. “The potential of generative \\nAI for personalized persuasion at scale.” Scientific Reports 14 (1): 4692. https://doi.org/10.1038/s41598-024-\\n53755-0.\\nMehrabi, Ninareh, Fred Morstatter, Nripsuta Saxena, Kristina Lerman and Aram Galstyan. 2021. “A Survey on Bias'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper1.pdf', 'page': 30}, page_content='and Fairness in Machine Learning.” ACM Computing Surveys  54 (6): 1–35. https://doi.org/10.1145/3457607.\\nMinistry of Foreign Affairs, People’s Republic of China. 2023. “Global AI Governance Initiative.” October 30.  \\nwww.mfa.gov.cn/eng/wjdt_665385/2649_665393/202310/t20231020_11164834.html .\\nMorris, Meredith Ringel, Jascha Sohl-Dickstein, Noah Fiedel, Tris Warkentin, Allan Dafoe, Aleksandra Faust, Clement \\nFarabet and Shane Legg. 2024. “Position: Levels of AGI for Operationalizing Progress on the Path to AGI.” \\nProceedings of the 41st International Conference on Machine Learning . Vienna, Austria.  \\nhttps://arxiv.org/pdf/2311.02462.\\nMuzahid, Abu Jafar Md, Syafiq Fauzi Kamarulzaman, Md Arafatur Rahman, Saydul Akbar Murad, Md Abdus Samad \\nKamal and Ali H. Alenezi. 2023. “Multiple vehicle cooperation and collision avoidance in automated vehicles: \\nSurvey and an AI-enabled conceptual framework.” Scientific Reports  13 (1): 603. www.nature.com/articles/\\ns41598-022-27026-9 .'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper1.pdf', 'page': 30}, page_content='s41598-022-27026-9 .\\nNational Cyber Security Centre. 2024. “The near-term impact of AI on the cyber threat.” UK Government,  \\nJanuary 24. www.ncsc.gov.uk/report/impact-of-ai-on-cyber-threat.\\nNolan, Beatrice. 2023. “Don’t let Big Tech write the AI rules, warns AI godfather.” Business Insider , November 4. \\nwww.businessinsider.com/big-tech-controlling-ai-sector-concerns-ai-godfather-yoshua-bengio-2023-11.'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper1.pdf', 'page': 31}, page_content='28O’Keefe, Cullen, Peter Cihon, Ben Garfinkel, Carrick Flynn, Jade Leung and Allan Dafoe. 2020. The Windfall \\nClause: Distributing the Benefits of AI for the Common Good . Future of Humanity Institute, University of \\nOxford. www.fhi.ox.ac.uk/wp-content/uploads/Windfall-Clause-Report.pdf.\\nOpenAI. 2023. “GPT-4 System Card.” March 23. https://cdn.openai.com/papers/gpt-4-system-card.pdf.\\nPasseri, Paolo. 2023. “The Risk of Accidental Data Exposure by Generative AI is Growing.” Infosecurity \\nMagazine (blog), August 16. www.infosecurity-magazine.com/blogs/accidental-data-exposure-gen-ai/.\\nPeterson, Dahlia and Samantha Hoffman. 2022. “Geopolitical implications of AI and digital surveillance \\nadoption.” Brookings Institution, June. www.brookings.edu/articles/geopolitical-implications-of-ai-and-\\ndigital-surveillance-adoption/.\\nPiper, Kelsey. 2020. “The case for taking AI seriously as a threat to humanity.” Vox, October 15.'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper1.pdf', 'page': 31}, page_content='Piper, Kelsey. 2020. “The case for taking AI seriously as a threat to humanity.” Vox, October 15.  \\nwww.vox.com/future-perfect/2018/12/21/18126576/ai-artificial-intelligence-machine-  \\nlearning-safety-alignment .\\nSandbrink, Jonas B. 2023. “Artificial intelligence and biological misuse: Differentiating risks of language \\nmodels and biological design tools.” arXiv, December 23. https://doi.org/10.48550/arXiv.2306.13952.\\nSastry, Girish, Lennart Heim, Haydn Belfield, Markus Anderljung, Miles Brundage, Julian Hazell, Cullen \\nO’Keefe et al. 2024. “Computing Power and the Governance of Artificial Intelligence.” arXiv, \\nFebruary 13. https://doi.org/10.48550/arXiv.2402.08797.\\nScharre, Paul. 2023. Four battlegrounds: power in the age of artificial intelligence . W. W. Norton & \\nCompany.\\nSchneier, Bruce and Davi Ottenheimer. 2023. “Robots Are Already Killing People.” The Atlantic , \\nSeptember 6. www.theatlantic.com/technology/archive/2023/09/robot-safety-standards-'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper1.pdf', 'page': 31}, page_content='September 6. www.theatlantic.com/technology/archive/2023/09/robot-safety-standards-  \\nregulation-human-fatalities/675231/.\\nSebo, Jeff and Robert Long. 2023. “Moral consideration for AI systems by 2030.” AI and Ethics . \\nhttps://doi.org/10.1007/s43681-023-00379-1.\\nSevilla, Jaime and Edu Roldán. 2024. “Training Compute of Frontier AI Models Grows by 4–5x Per Year.” \\nEpoch AI, May 28. https://epochai.org/blog/training-compute-of-frontier-ai-models-grows-by-4-5x-per-\\nyear.\\nShah, Rohin, Vikrant Varma, Ramana Kumar, Mary Phuong, Victoria Krakovna, Jonathan Uesato and Zac \\nKenton. 2022. “Goal Misgeneralization: Why Correct Specifications Aren’t Enough For Correct Goals.” \\narXiv, November 2. https://doi.org/10.48550/arXiv.2210.01790.\\nShevlane, Toby, Sebastian Farquhar, Ben Garfinkel, Mary Phuong, Jess Whittlestone, Jade Leung, Daniel \\nKokotajlo et al. 2023. “Model evaluation for extreme risks.” arXiv, September 22. http://arxiv.org/\\nabs/2305.15324.'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper1.pdf', 'page': 31}, page_content='abs/2305.15324.\\nTrager, Robert F., Ben Harack, Anka Reuel, Allison Carnegie, Lennart Heim, Lewis Ho, Sarah Kreps et \\nal. 2023. “International Governance of Civilian AI: A Jurisdictional Certification Approach.” arXiv, \\nSeptember 11. https://doi.org/10.48550/arXiv.2308.15514.\\nUnited Nations. 2021. Our Common Agenda: Report of the Secretary-General . New York, NY:  \\nUnited Nations. www.un.org/en/content/common-agenda-report/assets/pdf/  \\nCommon_Agenda_Report_English.pdf .\\nUnited Nations General Assembly. 2024. “Seizing the opportunities of safe, secure and trustworthy artificial \\nintelligence systems for sustainable development.” A/78/L.49. https://daccess-ods.un.org/access.nsf/\\nGet?OpenAgent&DS=A/RES/78/265&Lang=E.\\nUrbina, Fabio, Filippa Lentzos, Cédric Invernizzi and Sean Ekins. 2022. “Dual use of artificial-intelligence-\\npowered drug discovery.” Nature Machine Intelligence  4 (3): 189–91. https://doi.org/10.1038/s42256-\\n022-00465-9.'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper1.pdf', 'page': 33}, page_content='About CIGI  \\nThe Centre for International Governance Innovation (CIGI) is an \\nindependent, non-partisan think tank whose peer-reviewed research \\nand trusted analysis influence policy makers to innovate. Our global \\nnetwork of multidisciplinary researchers and strategic partnerships \\nprovide policy solutions for the digital era with one goal: to improve \\npeople’s lives everywhere. Headquartered in Waterloo, Canada, CIGI \\nhas received support from the Government of Canada, the Government \\nof Ontario and founder Jim Balsillie.  \\n \\nÀ propos du CIGI  \\nLe Centre pour l’innovation dans la gouvernance internationale (CIGI) \\nest un groupe de réflexion indépendant et non partisan dont les \\nrecherches évaluées par des pairs et les analyses fiables incitent \\nles décideurs à innover. Grâce à son réseau mondial de chercheurs \\npluridisciplinaires et de partenariats stratégiques, le CIGI offre des \\nsolutions politiques adaptées à l’ère numérique dans le seul but'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper1.pdf', 'page': 33}, page_content='solutions politiques adaptées à l’ère numérique dans le seul but \\nd’améliorer la vie des gens du monde entier. Le CIGI, dont le siège se \\ntrouve à Waterloo, au Canada, bénéficie du soutien du gouvernement \\ndu Canada, du gouvernement de l’Ontario et de son fondateur, Jim \\nBalsillie. \\n67 Erb Street West  \\nWaterloo, ON, Canada N2L 6C2\\nwww.cigionline.org')]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d24411ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "cb43bd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\"\n",
    "model_kwargs = {'device': 'cpu'}\n",
    "encode_kwargs = {'normalize_embeddings': False}\n",
    "embedding = HuggingFaceEmbeddings(model_name=model_name,\n",
    "                                  model_kwargs=model_kwargs,\n",
    "                                  encode_kwargs=encode_kwargs)\n",
    "#векторная бд\n",
    "vector_store_to_load = FAISS.from_documents(docdir, embedding=embedding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8fd965c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper0.pdf', 'page': 5}, page_content='1. What is artificial intelligence?\\nArtificial intelligence (AI) is “a system’s ability to interpret external data correctly, to \\nlearn from such data, and to use those learnings to achieve specific goals and tasks \\nthrough flexible adaptation” (Kaplan and Haenlein, 2019).  The modern conception of \\nAI refers to “agents” or systems that can perform actions based on their perception of \\nthe environment (Russell and Norvig, 2020). Inspired by this conception that sees AI \\nsystems as agents, the OECD has defined AI as a machine-based system that, for explicit \\nor implicit objectives, infers how to create outputs from the inputs it receives (e.g., data), \\ndelivering predictions, content, recommendations, or decisions as a result.1  Even though \\ndefinitions of AI tend to highlight the processing of information and its results, the OECD’s \\ndefinition also emphasises the importance of looking at its objectives, as AI systems can'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper0.pdf', 'page': 3}, page_content='4\\nArtificial intelligence (AI) refers to systems that can process information, \\nlearn from it, and use that learning to generate outputs and achieve goals \\n(Kaplan and Haenlein, 2019). Generative artificial intelligence involves using \\nvarious models to create content such as text, images, video, or sound. Generative \\nAI has the potential to contribute between $2.6 trillion and $4.4 trillion annually to \\nthe global economy, highlighting its positive economic effects \\n(McKinsey & Company, 2023).\\nThe key impacts of AI on employment are related to job displacement, \\naugmentation, and creation. While some jobs may be displaced, others will \\nsee growth due to AI implementation, particularly in fields like AI modelling and \\nbusiness intelligence (WEF, 2023a). There is strong potential for the creation of new \\njobs, as can be observed over recent years. Generative AI models may increase \\nthe value of jobs requiring social interactions, while the augmentation potential'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper0.pdf', 'page': 5}, page_content='definition also emphasises the importance of looking at its objectives, as AI systems can \\nbe assessed as beneficial or not based on the aims that are set for them (Russell, 2019).\\n2. What is generative artificial intelligence?\\nWhereas the understanding of AI as “making machines capable of simulating \\nintelligence” is straightforward and uncontroversial (Wamba-Taguimdje et al., 2020), there \\nare recurrent issues in the history of AI that have been subject to societal discussion, \\nsuch as job displacements, failings in automated systems and privacy protections \\n(Buchanan, 2005). Current debates revolve around similar issues, but this time the impact \\nof “generative AI” is in the spotlight. Generative AI uses different models as a foundation \\nto create content in formats such as text, images, video or sound. The most resonant of \\nthem at present are “large language models” (LLMs) such as Chat-GPT or Gemini. LLMs'),\n",
       " Document(metadata={'source': 'C:\\\\Work\\\\Rag\\\\papers\\\\paper1.pdf', 'page': 4}, page_content='1Executive Summary\\nAdvanced artificial intelligence (AI) could be the most powerful technology ever created by \\nhumans,  unleashing explosive growth in cognitive capability that transforms all aspects of society \\nand shapes the future trajectory of civilization. Such a transformation presents unprecedented global \\nchallenges. Humanity must realize and distribute global benefits from AI, address global AI risks and \\nmake globally legitimate and effective decisions about how to govern advanced AI. This will require \\nthe very best of human ingenuity, wisdom and global cooperation over the coming years. \\nFuture developments in AI could bring enormous global benefits,  with the potential to accelerate \\nscientific discovery, spur technological innovation and massively increase prosperity. However, \\nthese benefits cannot be realized and fairly distributed through national policies or market forces')]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store_to_load.similarity_search('Что такое AI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "26118a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding_retriever_load = vector_store_to_load.as_retriever(search_kwargs={'k': 3}, search_type=\"mmr\")\n",
    "vector_store_to_load.save_local(\"C:\\Work\\Rag\\DB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a6025f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_store = FAISS.load_local(\"C:\\Work\\Rag\\DB\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
